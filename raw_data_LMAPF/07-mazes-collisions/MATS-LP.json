[{"metrics": {"avg_throughput": 0.40234375, "avg_agents_density": 0.03120819364119237, "a_collisions": 13, "o_collisions": 0, "runtime": 28.82142884004861}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-000"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.49609375, "avg_agents_density": 0.041155616090974886, "a_collisions": 19, "o_collisions": 0, "runtime": 26.617831576615572}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-001"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.48828125, "avg_agents_density": 0.033600284853995716, "a_collisions": 16, "o_collisions": 0, "runtime": 27.039173093624413}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-002"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.49609375, "avg_agents_density": 0.03552893138437951, "a_collisions": 10, "o_collisions": 0, "runtime": 32.54606543108821}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-003"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44140625, "avg_agents_density": 0.03461857957801738, "a_collisions": 25, "o_collisions": 0, "runtime": 23.558385689742863}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-004"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.37109375, "avg_agents_density": 0.03701791702698783, "a_collisions": 18, "o_collisions": 0, "runtime": 24.459692606702447}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-005"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4765625, "avg_agents_density": 0.03613947943689019, "a_collisions": 8, "o_collisions": 0, "runtime": 32.01003772672266}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-006"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.40625, "avg_agents_density": 0.0402585934693116, "a_collisions": 22, "o_collisions": 0, "runtime": 26.97779892012477}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-007"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4921875, "avg_agents_density": 0.03756967249205253, "a_collisions": 18, "o_collisions": 0, "runtime": 26.089720498770475}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-008"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.515625, "avg_agents_density": 0.037261679544398504, "a_collisions": 18, "o_collisions": 0, "runtime": 27.94362009689212}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-009"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.41015625, "avg_agents_density": 0.028769781737439385, "a_collisions": 15, "o_collisions": 0, "runtime": 27.10500675905496}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-010"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4296875, "avg_agents_density": 0.04217878681143686, "a_collisions": 27, "o_collisions": 0, "runtime": 34.65068096015602}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-011"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4921875, "avg_agents_density": 0.04051929776310187, "a_collisions": 11, "o_collisions": 0, "runtime": 25.084763151593506}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-012"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.48046875, "avg_agents_density": 0.03791395099539284, "a_collisions": 20, "o_collisions": 0, "runtime": 27.85961110610515}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-013"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.51953125, "avg_agents_density": 0.04395366466006563, "a_collisions": 25, "o_collisions": 0, "runtime": 33.35588842909783}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-014"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4375, "avg_agents_density": 0.03407580207378555, "a_collisions": 15, "o_collisions": 0, "runtime": 23.878042331896722}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-015"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.484375, "avg_agents_density": 0.03602537490416992, "a_collisions": 8, "o_collisions": 0, "runtime": 25.379634459502995}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-016"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4375, "avg_agents_density": 0.030466789338643833, "a_collisions": 18, "o_collisions": 0, "runtime": 25.83162776660174}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-017"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.39453125, "avg_agents_density": 0.034055104893370394, "a_collisions": 12, "o_collisions": 0, "runtime": 24.740825061686337}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-018"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.3515625, "avg_agents_density": 0.04090658381752115, "a_collisions": 27, "o_collisions": 0, "runtime": 28.272451114840806}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-019"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.39453125, "avg_agents_density": 0.03021801872598731, "a_collisions": 14, "o_collisions": 0, "runtime": 28.941894474439323}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-020"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44140625, "avg_agents_density": 0.03637638388500882, "a_collisions": 18, "o_collisions": 0, "runtime": 23.793009201064706}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-021"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46484375, "avg_agents_density": 0.028389873096906392, "a_collisions": 14, "o_collisions": 0, "runtime": 24.813849528320134}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-022"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46875, "avg_agents_density": 0.04285122651945809, "a_collisions": 32, "o_collisions": 0, "runtime": 36.9071155320853}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-023"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.37890625, "avg_agents_density": 0.033671923568681844, "a_collisions": 17, "o_collisions": 0, "runtime": 24.053730987012386}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-024"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.65234375, "avg_agents_density": 0.02705457910423488, "a_collisions": 12, "o_collisions": 0, "runtime": 28.93860691972077}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-025"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4609375, "avg_agents_density": 0.03339347763515774, "a_collisions": 15, "o_collisions": 0, "runtime": 27.004556478001177}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-026"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.42578125, "avg_agents_density": 0.03322932202210112, "a_collisions": 28, "o_collisions": 0, "runtime": 28.535149186849594}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-027"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.37109375, "avg_agents_density": 0.03427132675650816, "a_collisions": 17, "o_collisions": 0, "runtime": 29.454511678777635}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-028"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.515625, "avg_agents_density": 0.04098222687939255, "a_collisions": 16, "o_collisions": 0, "runtime": 24.115460344590247}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-029"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.49609375, "avg_agents_density": 0.03635447455784331, "a_collisions": 18, "o_collisions": 0, "runtime": 26.567621683701873}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-030"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.54296875, "avg_agents_density": 0.03182768215224077, "a_collisions": 24, "o_collisions": 0, "runtime": 36.837340008467436}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-031"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46484375, "avg_agents_density": 0.035937992505387616, "a_collisions": 13, "o_collisions": 0, "runtime": 28.866659400053322}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-032"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4375, "avg_agents_density": 0.03413249174196488, "a_collisions": 16, "o_collisions": 0, "runtime": 30.261622607707977}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-033"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.578125, "avg_agents_density": 0.047100433367467213, "a_collisions": 31, "o_collisions": 0, "runtime": 28.869594451971352}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-034"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.546875, "avg_agents_density": 0.03792294655747683, "a_collisions": 28, "o_collisions": 0, "runtime": 31.385927132330835}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-035"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.546875, "avg_agents_density": 0.03419211909904033, "a_collisions": 14, "o_collisions": 0, "runtime": 26.85379293281585}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-036"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.47265625, "avg_agents_density": 0.03950391050910003, "a_collisions": 16, "o_collisions": 0, "runtime": 28.239168073982}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-037"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.50390625, "avg_agents_density": 0.029873117966191493, "a_collisions": 17, "o_collisions": 0, "runtime": 29.123040886595845}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-038"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44140625, "avg_agents_density": 0.03446458032900378, "a_collisions": 25, "o_collisions": 0, "runtime": 26.453171592205763}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-039"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.41015625, "avg_agents_density": 0.03536997959229863, "a_collisions": 14, "o_collisions": 0, "runtime": 25.186089678667486}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-040"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.36328125, "avg_agents_density": 0.039351613480168614, "a_collisions": 17, "o_collisions": 0, "runtime": 32.260181015357375}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-041"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5078125, "avg_agents_density": 0.03692908938032864, "a_collisions": 14, "o_collisions": 0, "runtime": 28.611796761862934}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-042"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.54296875, "avg_agents_density": 0.027563273965953504, "a_collisions": 12, "o_collisions": 0, "runtime": 28.587398258037865}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-043"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46484375, "avg_agents_density": 0.031560373791419884, "a_collisions": 25, "o_collisions": 0, "runtime": 26.095618722960353}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-044"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.40234375, "avg_agents_density": 0.033506274288647046, "a_collisions": 13, "o_collisions": 0, "runtime": 23.316239555366337}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-045"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5390625, "avg_agents_density": 0.030827822971738934, "a_collisions": 22, "o_collisions": 0, "runtime": 32.20411454513669}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-046"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44140625, "avg_agents_density": 0.037947415077824495, "a_collisions": 14, "o_collisions": 0, "runtime": 30.814741308800876}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-047"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.45703125, "avg_agents_density": 0.0340939024861449, "a_collisions": 14, "o_collisions": 0, "runtime": 25.783422894775867}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-048"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.53125, "avg_agents_density": 0.04386032324965902, "a_collisions": 28, "o_collisions": 0, "runtime": 28.35979845933616}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-049"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.39453125, "avg_agents_density": 0.037632864634688026, "a_collisions": 20, "o_collisions": 0, "runtime": 27.351888954639435}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-050"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46484375, "avg_agents_density": 0.033582240834001985, "a_collisions": 16, "o_collisions": 0, "runtime": 27.00878443196416}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-051"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.42578125, "avg_agents_density": 0.03405075674052624, "a_collisions": 13, "o_collisions": 0, "runtime": 24.928986510261893}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-052"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.34765625, "avg_agents_density": 0.0455514283767971, "a_collisions": 63, "o_collisions": 0, "runtime": 31.561531961895525}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-053"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4453125, "avg_agents_density": 0.03321449329896729, "a_collisions": 29, "o_collisions": 0, "runtime": 25.401801732368767}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-054"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.453125, "avg_agents_density": 0.03313907439664422, "a_collisions": 19, "o_collisions": 0, "runtime": 25.76447729114443}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-055"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.578125, "avg_agents_density": 0.02490812564106922, "a_collisions": 11, "o_collisions": 0, "runtime": 30.75303820054978}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-056"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44140625, "avg_agents_density": 0.03991289246923339, "a_collisions": 21, "o_collisions": 0, "runtime": 27.857937204651535}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-057"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.36328125, "avg_agents_density": 0.04501823913747692, "a_collisions": 29, "o_collisions": 0, "runtime": 28.68981530983001}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-058"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4140625, "avg_agents_density": 0.03494092393275999, "a_collisions": 15, "o_collisions": 0, "runtime": 24.727567831985652}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-059"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6484375, "avg_agents_density": 0.02992445114408661, "a_collisions": 12, "o_collisions": 0, "runtime": 31.44569364283234}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-060"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.453125, "avg_agents_density": 0.039550554785919664, "a_collisions": 21, "o_collisions": 0, "runtime": 25.053484439849854}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-061"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.39453125, "avg_agents_density": 0.03454678714970466, "a_collisions": 20, "o_collisions": 0, "runtime": 25.807886209338903}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-062"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.3828125, "avg_agents_density": 0.03308127695800851, "a_collisions": 17, "o_collisions": 0, "runtime": 25.84576121624559}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-063"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.47265625, "avg_agents_density": 0.03919484344677083, "a_collisions": 26, "o_collisions": 0, "runtime": 25.387569243088365}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-064"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5625, "avg_agents_density": 0.041867824558590616, "a_collisions": 18, "o_collisions": 0, "runtime": 25.914100664667785}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-065"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.43359375, "avg_agents_density": 0.03289605775188824, "a_collisions": 16, "o_collisions": 0, "runtime": 27.153240787796676}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-066"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.48828125, "avg_agents_density": 0.030398179698293525, "a_collisions": 17, "o_collisions": 0, "runtime": 31.085483874194324}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-067"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.47265625, "avg_agents_density": 0.039312498800806214, "a_collisions": 38, "o_collisions": 0, "runtime": 20.83170374389738}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-068"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.43359375, "avg_agents_density": 0.04037303279580255, "a_collisions": 14, "o_collisions": 0, "runtime": 23.135427036322653}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-069"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.40625, "avg_agents_density": 0.03493154754930633, "a_collisions": 20, "o_collisions": 0, "runtime": 29.727157003246248}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-070"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44140625, "avg_agents_density": 0.039812268334007014, "a_collisions": 31, "o_collisions": 0, "runtime": 26.773344569839537}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-071"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.546875, "avg_agents_density": 0.02424019658777452, "a_collisions": 8, "o_collisions": 0, "runtime": 24.97460574284196}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-072"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4765625, "avg_agents_density": 0.04072632433005621, "a_collisions": 14, "o_collisions": 0, "runtime": 29.05467895232141}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-073"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4453125, "avg_agents_density": 0.03026892845540436, "a_collisions": 17, "o_collisions": 0, "runtime": 27.83814249932766}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-074"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.484375, "avg_agents_density": 0.025254148581459638, "a_collisions": 22, "o_collisions": 0, "runtime": 27.976698407903314}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-075"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.3828125, "avg_agents_density": 0.03608132805089687, "a_collisions": 161, "o_collisions": 0, "runtime": 19.23121258150786}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-076"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.40234375, "avg_agents_density": 0.034618508324302244, "a_collisions": 9, "o_collisions": 0, "runtime": 22.514912001788616}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-077"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.49609375, "avg_agents_density": 0.0362879869324145, "a_collisions": 11, "o_collisions": 0, "runtime": 29.223619288764894}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-078"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5078125, "avg_agents_density": 0.030502615383431332, "a_collisions": 18, "o_collisions": 0, "runtime": 30.61401845421642}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-079"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.55859375, "avg_agents_density": 0.027228245495309337, "a_collisions": 17, "o_collisions": 0, "runtime": 26.618158909492195}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-080"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5, "avg_agents_density": 0.030868376189744036, "a_collisions": 20, "o_collisions": 0, "runtime": 26.967618538998067}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-081"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.38671875, "avg_agents_density": 0.0342404689858202, "a_collisions": 10, "o_collisions": 0, "runtime": 26.938994714990258}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-082"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5234375, "avg_agents_density": 0.02836657616842562, "a_collisions": 12, "o_collisions": 0, "runtime": 30.257165879942477}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-083"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.3671875, "avg_agents_density": 0.03644393195135242, "a_collisions": 8, "o_collisions": 0, "runtime": 19.026658116839826}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-084"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44921875, "avg_agents_density": 0.03711351986185245, "a_collisions": 18, "o_collisions": 0, "runtime": 23.607512499205768}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-085"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46875, "avg_agents_density": 0.030738835948705873, "a_collisions": 20, "o_collisions": 0, "runtime": 31.543580737896264}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-086"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.3203125, "avg_agents_density": 0.04655487872431472, "a_collisions": 23, "o_collisions": 0, "runtime": 26.698072561062872}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-087"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4140625, "avg_agents_density": 0.041066885098918024, "a_collisions": 15, "o_collisions": 0, "runtime": 25.612700598314404}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-088"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.50390625, "avg_agents_density": 0.0364902278305226, "a_collisions": 20, "o_collisions": 0, "runtime": 26.98850951809436}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-089"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44921875, "avg_agents_density": 0.038301158418676554, "a_collisions": 17, "o_collisions": 0, "runtime": 27.31865973211825}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-090"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.48828125, "avg_agents_density": 0.03729370971155532, "a_collisions": 16, "o_collisions": 0, "runtime": 29.342105897143483}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-091"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.51171875, "avg_agents_density": 0.027204552984164774, "a_collisions": 15, "o_collisions": 0, "runtime": 20.27467296551913}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-092"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.42578125, "avg_agents_density": 0.03558780760313599, "a_collisions": 16, "o_collisions": 0, "runtime": 21.177288316190243}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-093"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.43359375, "avg_agents_density": 0.041603438914000444, "a_collisions": 18, "o_collisions": 0, "runtime": 25.577519736252725}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-094"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.453125, "avg_agents_density": 0.03849702761092826, "a_collisions": 23, "o_collisions": 0, "runtime": 30.765309372916818}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-095"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.421875, "avg_agents_density": 0.03770521991324103, "a_collisions": 14, "o_collisions": 0, "runtime": 25.602220316417515}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-096"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.453125, "avg_agents_density": 0.03372094226112969, "a_collisions": 21, "o_collisions": 0, "runtime": 22.58191126678139}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-097"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4375, "avg_agents_density": 0.039564466338511003, "a_collisions": 23, "o_collisions": 0, "runtime": 32.11118998937309}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-098"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46484375, "avg_agents_density": 0.0341323809607349, "a_collisions": 19, "o_collisions": 0, "runtime": 25.544110753573477}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-099"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46875, "avg_agents_density": 0.03968522247742757, "a_collisions": 23, "o_collisions": 0, "runtime": 29.63450818043202}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-100"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.45703125, "avg_agents_density": 0.03665745918850213, "a_collisions": 22, "o_collisions": 0, "runtime": 31.5049714660272}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-101"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.53515625, "avg_agents_density": 0.042937754743137234, "a_collisions": 20, "o_collisions": 0, "runtime": 23.705041388981044}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-102"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4765625, "avg_agents_density": 0.03382975606266334, "a_collisions": 22, "o_collisions": 0, "runtime": 24.995621134527028}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-103"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4140625, "avg_agents_density": 0.03689772209436315, "a_collisions": 18, "o_collisions": 0, "runtime": 30.14136936608702}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-104"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.37890625, "avg_agents_density": 0.033376013907645316, "a_collisions": 16, "o_collisions": 0, "runtime": 24.0852914378047}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-105"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6171875, "avg_agents_density": 0.02872203413321635, "a_collisions": 17, "o_collisions": 0, "runtime": 29.736362494528294}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-106"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4140625, "avg_agents_density": 0.038732939083566516, "a_collisions": 8, "o_collisions": 0, "runtime": 25.28109198063612}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-107"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46875, "avg_agents_density": 0.0403711139587856, "a_collisions": 16, "o_collisions": 0, "runtime": 28.43253322597593}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-108"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.44921875, "avg_agents_density": 0.04288931204510889, "a_collisions": 20, "o_collisions": 0, "runtime": 32.94668949302286}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-109"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46484375, "avg_agents_density": 0.039927934523105314, "a_collisions": 26, "o_collisions": 0, "runtime": 21.95143804140389}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-110"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.58203125, "avg_agents_density": 0.03318883340158927, "a_collisions": 24, "o_collisions": 0, "runtime": 26.683179105632007}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-111"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.515625, "avg_agents_density": 0.039477841751456716, "a_collisions": 31, "o_collisions": 0, "runtime": 34.74881812278181}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-112"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.609375, "avg_agents_density": 0.030953814803761397, "a_collisions": 13, "o_collisions": 0, "runtime": 25.89829899277538}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-113"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.62109375, "avg_agents_density": 0.03458926763264995, "a_collisions": 18, "o_collisions": 0, "runtime": 28.329026397317648}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-114"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.421875, "avg_agents_density": 0.03329266418166574, "a_collisions": 14, "o_collisions": 0, "runtime": 24.633025532588363}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-115"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.546875, "avg_agents_density": 0.04260290773775815, "a_collisions": 26, "o_collisions": 0, "runtime": 30.109888187609613}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-116"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5625, "avg_agents_density": 0.03462309508344382, "a_collisions": 24, "o_collisions": 0, "runtime": 33.20366347115487}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-117"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4375, "avg_agents_density": 0.03470759916053379, "a_collisions": 13, "o_collisions": 0, "runtime": 18.288396193645895}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-118"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.421875, "avg_agents_density": 0.03758034404980717, "a_collisions": 13, "o_collisions": 0, "runtime": 23.08154872711748}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-119"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.51171875, "avg_agents_density": 0.025067585385187264, "a_collisions": 15, "o_collisions": 0, "runtime": 30.390274971723557}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-120"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.48046875, "avg_agents_density": 0.036150234861094345, "a_collisions": 21, "o_collisions": 0, "runtime": 23.158576532267034}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-121"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.4765625, "avg_agents_density": 0.028475971887052903, "a_collisions": 13, "o_collisions": 0, "runtime": 25.738730415701866}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-122"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5625, "avg_agents_density": 0.03311821805468058, "a_collisions": 20, "o_collisions": 0, "runtime": 29.130983737297356}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-123"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.36328125, "avg_agents_density": 0.03736011848946548, "a_collisions": 15, "o_collisions": 0, "runtime": 27.226410363800824}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-124"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.46875, "avg_agents_density": 0.03826141895859507, "a_collisions": 19, "o_collisions": 0, "runtime": 31.17640767712146}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-125"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.37890625, "avg_agents_density": 0.036972690099206215, "a_collisions": 22, "o_collisions": 0, "runtime": 21.113312204368412}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-126"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.55859375, "avg_agents_density": 0.032779808224640064, "a_collisions": 17, "o_collisions": 0, "runtime": 23.5331572862342}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-127"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8203125, "avg_agents_density": 0.06138640420111352, "a_collisions": 90, "o_collisions": 0, "runtime": 75.26207202859223}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-000"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.98046875, "avg_agents_density": 0.07122138011126106, "a_collisions": 93, "o_collisions": 0, "runtime": 79.94774328358471}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-001"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.88671875, "avg_agents_density": 0.05852978670628999, "a_collisions": 106, "o_collisions": 0, "runtime": 78.86056613922119}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-002"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.94921875, "avg_agents_density": 0.06307013282412396, "a_collisions": 82, "o_collisions": 0, "runtime": 85.47299394570291}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-003"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.75390625, "avg_agents_density": 0.054944643463474704, "a_collisions": 90, "o_collisions": 0, "runtime": 69.18005448952317}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-004"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.67578125, "avg_agents_density": 0.06448481326208842, "a_collisions": 76, "o_collisions": 0, "runtime": 67.91406396403909}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-005"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.75, "avg_agents_density": 0.06760229921220975, "a_collisions": 120, "o_collisions": 0, "runtime": 91.51203738898039}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-006"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.71484375, "avg_agents_density": 0.05927788290019642, "a_collisions": 100, "o_collisions": 0, "runtime": 71.96013543568552}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-007"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.89453125, "avg_agents_density": 0.06680407947088791, "a_collisions": 87, "o_collisions": 0, "runtime": 80.35277516953647}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-008"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.984375, "avg_agents_density": 0.06348994416736611, "a_collisions": 74, "o_collisions": 0, "runtime": 77.46928059775382}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-009"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.78125, "avg_agents_density": 0.04976288051549489, "a_collisions": 79, "o_collisions": 0, "runtime": 78.90017862059176}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-010"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.796875, "avg_agents_density": 0.07878520964783925, "a_collisions": 151, "o_collisions": 0, "runtime": 94.2384153706953}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-011"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.95703125, "avg_agents_density": 0.06699363230821327, "a_collisions": 142, "o_collisions": 0, "runtime": 72.95129630714655}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-012"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9921875, "avg_agents_density": 0.059917709715922876, "a_collisions": 75, "o_collisions": 0, "runtime": 70.81029894016683}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-013"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.94921875, "avg_agents_density": 0.0748565056738781, "a_collisions": 109, "o_collisions": 0, "runtime": 88.55410642269999}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-014"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8203125, "avg_agents_density": 0.05972715333664158, "a_collisions": 60, "o_collisions": 0, "runtime": 65.5866330601275}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-015"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8984375, "avg_agents_density": 0.06172835803791254, "a_collisions": 65, "o_collisions": 0, "runtime": 75.52518126089126}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-016"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8984375, "avg_agents_density": 0.05257286143225572, "a_collisions": 89, "o_collisions": 0, "runtime": 74.72555761877447}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-017"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.703125, "avg_agents_density": 0.06318427485646824, "a_collisions": 67, "o_collisions": 0, "runtime": 73.80830518528819}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-018"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.62109375, "avg_agents_density": 0.07482063059607234, "a_collisions": 167, "o_collisions": 0, "runtime": 80.47909644152969}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-019"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7734375, "avg_agents_density": 0.05264309370421913, "a_collisions": 85, "o_collisions": 0, "runtime": 62.089647429063916}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-020"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.84765625, "avg_agents_density": 0.0603762525458669, "a_collisions": 71, "o_collisions": 0, "runtime": 65.61786901019514}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-021"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.04591958768477468, "a_collisions": 74, "o_collisions": 0, "runtime": 78.12285224813968}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-022"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9296875, "avg_agents_density": 0.07059381271069666, "a_collisions": 105, "o_collisions": 0, "runtime": 78.6488542901352}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-023"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.74609375, "avg_agents_density": 0.05925258686377094, "a_collisions": 71, "o_collisions": 0, "runtime": 72.60228079929948}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-024"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2890625, "avg_agents_density": 0.05143970013179351, "a_collisions": 69, "o_collisions": 0, "runtime": 91.17718014866114}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-025"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.05247018918010105, "a_collisions": 93, "o_collisions": 0, "runtime": 74.07619194872677}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-026"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.77734375, "avg_agents_density": 0.051051090096892696, "a_collisions": 88, "o_collisions": 0, "runtime": 78.7981749298051}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-027"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.69921875, "avg_agents_density": 0.057561642506382765, "a_collisions": 69, "o_collisions": 0, "runtime": 62.22338872216642}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-028"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.94140625, "avg_agents_density": 0.07089749309389176, "a_collisions": 96, "o_collisions": 0, "runtime": 79.2045888453722}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-029"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9140625, "avg_agents_density": 0.06501985465974426, "a_collisions": 90, "o_collisions": 0, "runtime": 82.71504636947066}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-030"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.08984375, "avg_agents_density": 0.05881929704901793, "a_collisions": 100, "o_collisions": 0, "runtime": 102.32724529597908}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-031"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8203125, "avg_agents_density": 0.059221148615328595, "a_collisions": 73, "o_collisions": 0, "runtime": 66.22079429402947}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-032"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7734375, "avg_agents_density": 0.06304795674420134, "a_collisions": 102, "o_collisions": 0, "runtime": 77.52583775296807}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-033"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0390625, "avg_agents_density": 0.07886267038086965, "a_collisions": 185, "o_collisions": 0, "runtime": 91.9743663361296}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-034"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.94140625, "avg_agents_density": 0.06150965634958195, "a_collisions": 143, "o_collisions": 0, "runtime": 92.59848621673882}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-035"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.93359375, "avg_agents_density": 0.06242048969160623, "a_collisions": 104, "o_collisions": 0, "runtime": 78.52992366347462}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-036"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8828125, "avg_agents_density": 0.06529155699680622, "a_collisions": 101, "o_collisions": 0, "runtime": 76.23915934562683}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-037"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9375, "avg_agents_density": 0.05380151296996841, "a_collisions": 83, "o_collisions": 0, "runtime": 80.07053747493774}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-038"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.796875, "avg_agents_density": 0.06323893244545095, "a_collisions": 134, "o_collisions": 0, "runtime": 83.94818921107799}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-039"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6796875, "avg_agents_density": 0.06595667048553912, "a_collisions": 123, "o_collisions": 0, "runtime": 73.83175289258361}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-040"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.65234375, "avg_agents_density": 0.059142066728748076, "a_collisions": 75, "o_collisions": 0, "runtime": 72.48571601230651}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-041"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.88671875, "avg_agents_density": 0.06665118064624724, "a_collisions": 96, "o_collisions": 0, "runtime": 88.364127965644}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-042"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.140625, "avg_agents_density": 0.04878017998866739, "a_collisions": 52, "o_collisions": 0, "runtime": 84.22470331657678}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-043"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.890625, "avg_agents_density": 0.05488027519232862, "a_collisions": 110, "o_collisions": 0, "runtime": 79.2313781408593}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-044"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6796875, "avg_agents_density": 0.06232093629523229, "a_collisions": 87, "o_collisions": 0, "runtime": 72.47273270599544}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-045"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.046875, "avg_agents_density": 0.0501332897645176, "a_collisions": 78, "o_collisions": 0, "runtime": 86.1251764362678}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-046"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.83203125, "avg_agents_density": 0.06969881955219918, "a_collisions": 124, "o_collisions": 0, "runtime": 80.58225063420832}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-047"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.81640625, "avg_agents_density": 0.0637112881283177, "a_collisions": 122, "o_collisions": 0, "runtime": 84.80087921768427}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-048"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.00390625, "avg_agents_density": 0.07667127097285809, "a_collisions": 106, "o_collisions": 0, "runtime": 82.81487280875444}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-049"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.734375, "avg_agents_density": 0.059250048740160176, "a_collisions": 63, "o_collisions": 0, "runtime": 72.50362781994045}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-050"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.05742000436962477, "a_collisions": 67, "o_collisions": 0, "runtime": 75.65415963623673}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-051"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.80859375, "avg_agents_density": 0.05867648163104187, "a_collisions": 85, "o_collisions": 0, "runtime": 74.28971308190376}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-052"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.55078125, "avg_agents_density": 0.08201761099888598, "a_collisions": 139, "o_collisions": 0, "runtime": 81.96409833431244}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-053"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.78515625, "avg_agents_density": 0.051269683037676345, "a_collisions": 80, "o_collisions": 0, "runtime": 74.91430648975074}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-054"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.89453125, "avg_agents_density": 0.061240392108335484, "a_collisions": 68, "o_collisions": 0, "runtime": 79.32049748208374}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-055"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09765625, "avg_agents_density": 0.044689758459244874, "a_collisions": 51, "o_collisions": 0, "runtime": 79.09147345647216}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-056"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.74609375, "avg_agents_density": 0.07033743478175815, "a_collisions": 111, "o_collisions": 0, "runtime": 85.677480019629}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-057"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.53515625, "avg_agents_density": 0.07739303536892891, "a_collisions": 107, "o_collisions": 0, "runtime": 86.94251744728535}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-058"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6953125, "avg_agents_density": 0.05836525369978616, "a_collisions": 86, "o_collisions": 0, "runtime": 71.56456386111677}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-059"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.34765625, "avg_agents_density": 0.052778699220613776, "a_collisions": 65, "o_collisions": 0, "runtime": 94.05084360390902}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-060"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.84765625, "avg_agents_density": 0.06947189579149525, "a_collisions": 90, "o_collisions": 0, "runtime": 77.21825688891113}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-061"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.734375, "avg_agents_density": 0.06075682079207427, "a_collisions": 95, "o_collisions": 0, "runtime": 74.56711925659329}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-062"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.609375, "avg_agents_density": 0.05757095642327993, "a_collisions": 186, "o_collisions": 0, "runtime": 74.91605149954557}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-063"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8515625, "avg_agents_density": 0.06759998257106535, "a_collisions": 100, "o_collisions": 0, "runtime": 70.23080100491643}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-064"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90234375, "avg_agents_density": 0.07628057147796474, "a_collisions": 110, "o_collisions": 0, "runtime": 75.21178165078163}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-065"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.78125, "avg_agents_density": 0.059057385527360895, "a_collisions": 98, "o_collisions": 0, "runtime": 68.07173050381243}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-066"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9921875, "avg_agents_density": 0.050807387933523615, "a_collisions": 60, "o_collisions": 0, "runtime": 77.29031090252101}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-067"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.87109375, "avg_agents_density": 0.06638257570184582, "a_collisions": 110, "o_collisions": 0, "runtime": 66.54219552874565}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-068"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.67578125, "avg_agents_density": 0.07433098531225336, "a_collisions": 130, "o_collisions": 0, "runtime": 74.06522811204195}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-069"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.76953125, "avg_agents_density": 0.06341725233608066, "a_collisions": 84, "o_collisions": 0, "runtime": 76.27336736861616}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-070"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.859375, "avg_agents_density": 0.06343352601717538, "a_collisions": 100, "o_collisions": 0, "runtime": 69.45125578157604}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-071"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.125, "avg_agents_density": 0.04208957129207867, "a_collisions": 50, "o_collisions": 0, "runtime": 73.29779427405447}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-072"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.96484375, "avg_agents_density": 0.06567543168490768, "a_collisions": 79, "o_collisions": 0, "runtime": 72.48475372511894}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-073"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.765625, "avg_agents_density": 0.05136330562762175, "a_collisions": 89, "o_collisions": 0, "runtime": 72.44472517352551}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-074"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.984375, "avg_agents_density": 0.0447176823288451, "a_collisions": 65, "o_collisions": 0, "runtime": 75.1047995928675}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-075"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7265625, "avg_agents_density": 0.06110592172352656, "a_collisions": 216, "o_collisions": 0, "runtime": 60.45519925002009}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-076"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.65234375, "avg_agents_density": 0.06247775043616783, "a_collisions": 86, "o_collisions": 0, "runtime": 66.13594402559102}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-077"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.921875, "avg_agents_density": 0.06589702637031661, "a_collisions": 61, "o_collisions": 0, "runtime": 78.03727356065065}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-078"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.08984375, "avg_agents_density": 0.05264839855832146, "a_collisions": 63, "o_collisions": 0, "runtime": 77.00267438869923}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-079"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1875, "avg_agents_density": 0.0442188315589597, "a_collisions": 39, "o_collisions": 0, "runtime": 74.94763809349388}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-080"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.96875, "avg_agents_density": 0.059198949331701556, "a_collisions": 96, "o_collisions": 0, "runtime": 77.93279476184398}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-081"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.69140625, "avg_agents_density": 0.0629995299527469, "a_collisions": 125, "o_collisions": 0, "runtime": 73.48978226445615}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-082"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.08203125, "avg_agents_density": 0.04918503561686256, "a_collisions": 74, "o_collisions": 0, "runtime": 82.71347505040467}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-083"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7109375, "avg_agents_density": 0.05759250901386988, "a_collisions": 58, "o_collisions": 0, "runtime": 56.897691550664604}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-084"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.78125, "avg_agents_density": 0.06923993475721166, "a_collisions": 139, "o_collisions": 0, "runtime": 68.96793443523347}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-085"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.953125, "avg_agents_density": 0.05052661762523804, "a_collisions": 68, "o_collisions": 0, "runtime": 76.21315553039312}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-086"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.57421875, "avg_agents_density": 0.0770636592655183, "a_collisions": 150, "o_collisions": 0, "runtime": 79.56972241029143}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-087"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6875, "avg_agents_density": 0.0683303744257516, "a_collisions": 101, "o_collisions": 0, "runtime": 70.89632391463965}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-088"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.96875, "avg_agents_density": 0.060616801083197336, "a_collisions": 75, "o_collisions": 0, "runtime": 73.08093083836138}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-089"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.83984375, "avg_agents_density": 0.06442272038706923, "a_collisions": 92, "o_collisions": 0, "runtime": 65.89659393858165}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-090"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9296875, "avg_agents_density": 0.0671835955820588, "a_collisions": 66, "o_collisions": 0, "runtime": 66.41506408620626}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-091"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0234375, "avg_agents_density": 0.04667671625781856, "a_collisions": 58, "o_collisions": 0, "runtime": 82.60699168406427}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-092"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.82421875, "avg_agents_density": 0.055243520082446464, "a_collisions": 53, "o_collisions": 0, "runtime": 58.10185708478093}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-093"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.79296875, "avg_agents_density": 0.07491936180604583, "a_collisions": 91, "o_collisions": 0, "runtime": 65.22688848059624}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-094"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.80859375, "avg_agents_density": 0.06521491887531362, "a_collisions": 70, "o_collisions": 0, "runtime": 72.57930683158338}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-095"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8125, "avg_agents_density": 0.062340676488835435, "a_collisions": 64, "o_collisions": 0, "runtime": 64.3439834099263}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-096"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8515625, "avg_agents_density": 0.0594847344915173, "a_collisions": 68, "o_collisions": 0, "runtime": 69.32592837419361}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-097"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7890625, "avg_agents_density": 0.06642378736243756, "a_collisions": 183, "o_collisions": 0, "runtime": 77.75513782631606}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-098"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.88671875, "avg_agents_density": 0.06233237966978726, "a_collisions": 72, "o_collisions": 0, "runtime": 74.80366103351116}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-099"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.96875, "avg_agents_density": 0.06178928363695627, "a_collisions": 78, "o_collisions": 0, "runtime": 75.55461508780718}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-100"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.890625, "avg_agents_density": 0.061467181547405006, "a_collisions": 95, "o_collisions": 0, "runtime": 79.07628331612796}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-101"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9921875, "avg_agents_density": 0.07311139221618936, "a_collisions": 94, "o_collisions": 0, "runtime": 75.88288250472397}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-102"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.96875, "avg_agents_density": 0.058544901934825366, "a_collisions": 101, "o_collisions": 0, "runtime": 74.68954934552312}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-103"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.78515625, "avg_agents_density": 0.06393633120845235, "a_collisions": 96, "o_collisions": 0, "runtime": 79.19374695327133}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-104"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6640625, "avg_agents_density": 0.0508678949457496, "a_collisions": 78, "o_collisions": 0, "runtime": 62.61273728311062}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-105"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.18359375, "avg_agents_density": 0.04896180348835798, "a_collisions": 77, "o_collisions": 0, "runtime": 79.36295462120324}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-106"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.734375, "avg_agents_density": 0.06718336223099937, "a_collisions": 139, "o_collisions": 0, "runtime": 73.28615807369351}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-107"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9296875, "avg_agents_density": 0.07439277266082765, "a_collisions": 107, "o_collisions": 0, "runtime": 82.84021999686956}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-108"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.84765625, "avg_agents_density": 0.0742707365919989, "a_collisions": 93, "o_collisions": 0, "runtime": 83.35106586571783}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-109"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8359375, "avg_agents_density": 0.06504336380089831, "a_collisions": 78, "o_collisions": 0, "runtime": 64.75710667297244}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-110"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.140625, "avg_agents_density": 0.06161068427175029, "a_collisions": 103, "o_collisions": 0, "runtime": 81.96144129987806}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-111"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.765625, "avg_agents_density": 0.06616396013914913, "a_collisions": 174, "o_collisions": 0, "runtime": 95.73956039827317}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-112"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.265625, "avg_agents_density": 0.057111548488223245, "a_collisions": 61, "o_collisions": 0, "runtime": 81.94880750030279}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-113"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1796875, "avg_agents_density": 0.05944923859915019, "a_collisions": 96, "o_collisions": 0, "runtime": 78.6075202524662}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-114"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.82421875, "avg_agents_density": 0.057313240705083174, "a_collisions": 52, "o_collisions": 0, "runtime": 65.3174148099497}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-115"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.01171875, "avg_agents_density": 0.07462343972465642, "a_collisions": 72, "o_collisions": 0, "runtime": 81.29329832177609}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-116"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.078125, "avg_agents_density": 0.06141275715248342, "a_collisions": 118, "o_collisions": 0, "runtime": 85.72970541846007}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-117"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8046875, "avg_agents_density": 0.06496314844097041, "a_collisions": 72, "o_collisions": 0, "runtime": 63.335753904655576}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-118"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.75, "avg_agents_density": 0.061022846288859345, "a_collisions": 86, "o_collisions": 0, "runtime": 67.86405498627573}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-119"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.98828125, "avg_agents_density": 0.04348922149068567, "a_collisions": 50, "o_collisions": 0, "runtime": 77.4432722600177}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-120"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.97265625, "avg_agents_density": 0.06465106320063552, "a_collisions": 77, "o_collisions": 0, "runtime": 72.51629285886884}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-121"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.94140625, "avg_agents_density": 0.0495014233978378, "a_collisions": 67, "o_collisions": 0, "runtime": 68.65110244695097}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-122"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.06640625, "avg_agents_density": 0.05884139262694514, "a_collisions": 107, "o_collisions": 0, "runtime": 90.58329424634576}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-123"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.625, "avg_agents_density": 0.06823291858464146, "a_collisions": 101, "o_collisions": 0, "runtime": 79.16741597093642}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-124"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8671875, "avg_agents_density": 0.065598190366643, "a_collisions": 102, "o_collisions": 0, "runtime": 81.33845358435065}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-125"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.671875, "avg_agents_density": 0.057446628653219804, "a_collisions": 109, "o_collisions": 0, "runtime": 63.30549986567348}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-126"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0703125, "avg_agents_density": 0.061461471293102, "a_collisions": 89, "o_collisions": 0, "runtime": 76.29884715285152}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-127"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.13671875, "avg_agents_density": 0.08946588840516267, "a_collisions": 218, "o_collisions": 0, "runtime": 143.35892369784415}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-000"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.30859375, "avg_agents_density": 0.1020090886474279, "a_collisions": 250, "o_collisions": 0, "runtime": 153.51293696276844}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-001"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.28125, "avg_agents_density": 0.08214749206781678, "a_collisions": 182, "o_collisions": 0, "runtime": 139.8558601969853}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-002"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2578125, "avg_agents_density": 0.0891775000899995, "a_collisions": 242, "o_collisions": 0, "runtime": 152.3012367989868}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-003"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.02734375, "avg_agents_density": 0.08330626546893255, "a_collisions": 250, "o_collisions": 0, "runtime": 156.8837802419439}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-004"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8984375, "avg_agents_density": 0.09409616375180863, "a_collisions": 181, "o_collisions": 0, "runtime": 132.8337698308751}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-005"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9375, "avg_agents_density": 0.09716677801424856, "a_collisions": 385, "o_collisions": 0, "runtime": 162.03325490746647}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-006"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.89453125, "avg_agents_density": 0.09179489219033593, "a_collisions": 246, "o_collisions": 0, "runtime": 141.23306546919048}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-007"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.19140625, "avg_agents_density": 0.10153042835948407, "a_collisions": 263, "o_collisions": 0, "runtime": 153.74312586896122}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-008"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3515625, "avg_agents_density": 0.09458797037023675, "a_collisions": 223, "o_collisions": 0, "runtime": 157.87415097188205}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-009"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.00390625, "avg_agents_density": 0.07684697895843451, "a_collisions": 273, "o_collisions": 0, "runtime": 167.22487318702042}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-010"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8828125, "avg_agents_density": 0.12383596196850816, "a_collisions": 495, "o_collisions": 0, "runtime": 179.75443747173995}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-011"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.33984375, "avg_agents_density": 0.09802800314823863, "a_collisions": 190, "o_collisions": 0, "runtime": 148.8814372541383}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-012"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.390625, "avg_agents_density": 0.08848746461414438, "a_collisions": 194, "o_collisions": 0, "runtime": 144.45753456186503}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-013"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2734375, "avg_agents_density": 0.10810725458777456, "a_collisions": 289, "o_collisions": 0, "runtime": 165.3337402874604}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-014"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.08203125, "avg_agents_density": 0.09478993461692271, "a_collisions": 274, "o_collisions": 0, "runtime": 144.74836468789726}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-015"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2109375, "avg_agents_density": 0.09131724815544204, "a_collisions": 198, "o_collisions": 0, "runtime": 148.6330777183175}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-016"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.25390625, "avg_agents_density": 0.07959739851273848, "a_collisions": 243, "o_collisions": 0, "runtime": 151.86752640176564}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-017"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.0927567971242664, "a_collisions": 204, "o_collisions": 0, "runtime": 135.8560673929751}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-018"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.84765625, "avg_agents_density": 0.09401405879909468, "a_collisions": 242, "o_collisions": 0, "runtime": 127.59876051172614}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-019"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.97265625, "avg_agents_density": 0.08070820486485815, "a_collisions": 243, "o_collisions": 0, "runtime": 135.59771725162864}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-020"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.15234375, "avg_agents_density": 0.08765009029853353, "a_collisions": 193, "o_collisions": 0, "runtime": 134.74975901469588}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-021"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.296875, "avg_agents_density": 0.068295252786513, "a_collisions": 179, "o_collisions": 0, "runtime": 145.1530290413648}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-022"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.203125, "avg_agents_density": 0.1014818406454771, "a_collisions": 277, "o_collisions": 0, "runtime": 161.23477185331285}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-023"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.99609375, "avg_agents_density": 0.08478697490431121, "a_collisions": 241, "o_collisions": 0, "runtime": 146.22653640527278}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-024"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.93359375, "avg_agents_density": 0.0767741389841023, "a_collisions": 158, "o_collisions": 0, "runtime": 180.76562889385968}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-025"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.23828125, "avg_agents_density": 0.07896060255697512, "a_collisions": 246, "o_collisions": 0, "runtime": 143.27908860333264}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-026"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.04296875, "avg_agents_density": 0.0747788308110072, "a_collisions": 317, "o_collisions": 0, "runtime": 138.17015661019832}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-027"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.921875, "avg_agents_density": 0.08545647198553519, "a_collisions": 191, "o_collisions": 0, "runtime": 127.28304254170507}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-028"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2734375, "avg_agents_density": 0.09992463782220418, "a_collisions": 247, "o_collisions": 0, "runtime": 151.26317692082375}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-029"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.265625, "avg_agents_density": 0.09986291819601437, "a_collisions": 264, "o_collisions": 0, "runtime": 159.50806216243654}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-030"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.55078125, "avg_agents_density": 0.08707734880109544, "a_collisions": 298, "o_collisions": 0, "runtime": 198.7618050724268}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-031"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.03515625, "avg_agents_density": 0.08844461706152164, "a_collisions": 216, "o_collisions": 0, "runtime": 149.11048243194818}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-032"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9453125, "avg_agents_density": 0.08972922919637548, "a_collisions": 353, "o_collisions": 0, "runtime": 140.0433795945719}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-033"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.43359375, "avg_agents_density": 0.11282559196721821, "a_collisions": 248, "o_collisions": 0, "runtime": 171.25088000763208}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-034"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.27734375, "avg_agents_density": 0.09430145605287502, "a_collisions": 386, "o_collisions": 0, "runtime": 186.4500835640356}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-035"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.296875, "avg_agents_density": 0.09503998559639287, "a_collisions": 255, "o_collisions": 0, "runtime": 156.3096942184493}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-036"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.11328125, "avg_agents_density": 0.10055516154787893, "a_collisions": 259, "o_collisions": 0, "runtime": 156.75089846830815}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-037"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2265625, "avg_agents_density": 0.07810946795579793, "a_collisions": 256, "o_collisions": 0, "runtime": 148.66266277618706}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-038"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.08950861642675755, "a_collisions": 350, "o_collisions": 0, "runtime": 162.73072399105877}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-039"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.87109375, "avg_agents_density": 0.09954366967501464, "a_collisions": 240, "o_collisions": 0, "runtime": 144.16347671020776}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-040"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8671875, "avg_agents_density": 0.08049564666320283, "a_collisions": 184, "o_collisions": 0, "runtime": 127.6769010135904}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-041"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1796875, "avg_agents_density": 0.09988015035128435, "a_collisions": 334, "o_collisions": 0, "runtime": 173.19842851534486}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-042"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.640625, "avg_agents_density": 0.0725589850680158, "a_collisions": 181, "o_collisions": 0, "runtime": 172.31436811573803}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-043"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.25, "avg_agents_density": 0.08024670140621638, "a_collisions": 215, "o_collisions": 0, "runtime": 154.15428054705262}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-044"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.97265625, "avg_agents_density": 0.08393284594016205, "a_collisions": 188, "o_collisions": 0, "runtime": 124.24898537341505}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-045"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.52734375, "avg_agents_density": 0.0726906296696387, "a_collisions": 174, "o_collisions": 0, "runtime": 163.46805836912245}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-046"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1328125, "avg_agents_density": 0.10054783771181842, "a_collisions": 214, "o_collisions": 0, "runtime": 145.90028008259833}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-047"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.11328125, "avg_agents_density": 0.09601051203096385, "a_collisions": 265, "o_collisions": 0, "runtime": 168.1953053753823}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-048"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.38671875, "avg_agents_density": 0.10348457933866953, "a_collisions": 243, "o_collisions": 0, "runtime": 154.435451134108}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-049"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9375, "avg_agents_density": 0.08894509599160494, "a_collisions": 228, "o_collisions": 0, "runtime": 143.69757663086057}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-050"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.24609375, "avg_agents_density": 0.0847375725308532, "a_collisions": 191, "o_collisions": 0, "runtime": 143.80236113537103}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-051"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.03125, "avg_agents_density": 0.0818680203252492, "a_collisions": 198, "o_collisions": 0, "runtime": 133.74255144130439}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-052"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.640625, "avg_agents_density": 0.11021899718692568, "a_collisions": 495, "o_collisions": 0, "runtime": 154.54539027251303}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-053"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09765625, "avg_agents_density": 0.07316456320050554, "a_collisions": 236, "o_collisions": 0, "runtime": 148.1849677739665}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-054"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1953125, "avg_agents_density": 0.08843868644429619, "a_collisions": 206, "o_collisions": 0, "runtime": 145.69549018796533}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-055"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.66796875, "avg_agents_density": 0.06486737604716636, "a_collisions": 115, "o_collisions": 0, "runtime": 161.62445244379342}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-056"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.11849048798668384, "a_collisions": 536, "o_collisions": 0, "runtime": 194.0497288396582}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-057"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.546875, "avg_agents_density": 0.10498962661136935, "a_collisions": 499, "o_collisions": 0, "runtime": 167.64107688236982}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-058"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8984375, "avg_agents_density": 0.08321541425543118, "a_collisions": 213, "o_collisions": 0, "runtime": 134.74694589152932}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-059"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.90625, "avg_agents_density": 0.07741495283802008, "a_collisions": 155, "o_collisions": 0, "runtime": 185.81149472109973}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-060"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.06640625, "avg_agents_density": 0.10354157155114758, "a_collisions": 260, "o_collisions": 0, "runtime": 150.4319297252223}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-061"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9453125, "avg_agents_density": 0.08898628836723396, "a_collisions": 231, "o_collisions": 0, "runtime": 151.45998787134886}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-062"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.81640625, "avg_agents_density": 0.08488787642859275, "a_collisions": 260, "o_collisions": 0, "runtime": 140.94258048664778}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-063"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.15234375, "avg_agents_density": 0.09938130361978777, "a_collisions": 227, "o_collisions": 0, "runtime": 139.66838617622852}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-064"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09765625, "avg_agents_density": 0.10559264453590035, "a_collisions": 295, "o_collisions": 0, "runtime": 153.828831942752}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-065"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.04296875, "avg_agents_density": 0.08605517648735682, "a_collisions": 248, "o_collisions": 0, "runtime": 139.1081268088892}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-066"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4140625, "avg_agents_density": 0.06770951358506895, "a_collisions": 153, "o_collisions": 0, "runtime": 134.02173734176904}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-067"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.16015625, "avg_agents_density": 0.09209498095408068, "a_collisions": 212, "o_collisions": 0, "runtime": 136.95975633431226}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-068"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.71875, "avg_agents_density": 0.1324006508550576, "a_collisions": 730, "o_collisions": 0, "runtime": 201.53364779427648}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-069"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.984375, "avg_agents_density": 0.08713245300655324, "a_collisions": 214, "o_collisions": 0, "runtime": 130.71849305648357}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-070"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9921875, "avg_agents_density": 0.09167211706168987, "a_collisions": 263, "o_collisions": 0, "runtime": 148.4400958912447}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-071"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.671875, "avg_agents_density": 0.06235249849900262, "a_collisions": 127, "o_collisions": 0, "runtime": 157.2291040867567}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-072"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.296875, "avg_agents_density": 0.0966229285537525, "a_collisions": 228, "o_collisions": 0, "runtime": 152.29264770820737}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-073"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.93359375, "avg_agents_density": 0.07370916590401225, "a_collisions": 240, "o_collisions": 0, "runtime": 152.2504254700616}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-074"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4296875, "avg_agents_density": 0.06311703981045029, "a_collisions": 156, "o_collisions": 0, "runtime": 133.37622025981545}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-075"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.98046875, "avg_agents_density": 0.09799896862679647, "a_collisions": 245, "o_collisions": 0, "runtime": 144.23318721260875}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-076"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.81640625, "avg_agents_density": 0.08827186479469705, "a_collisions": 264, "o_collisions": 0, "runtime": 139.27416702918708}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-077"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.296875, "avg_agents_density": 0.09770909636590694, "a_collisions": 198, "o_collisions": 0, "runtime": 139.1900227246806}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-078"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4921875, "avg_agents_density": 0.07532605770536706, "a_collisions": 148, "o_collisions": 0, "runtime": 165.11762018781155}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-079"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.66796875, "avg_agents_density": 0.06254009642846288, "a_collisions": 151, "o_collisions": 0, "runtime": 150.56842770893127}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-080"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2578125, "avg_agents_density": 0.0859192644541559, "a_collisions": 274, "o_collisions": 0, "runtime": 170.86185001954436}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-081"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.83203125, "avg_agents_density": 0.08991071500873028, "a_collisions": 239, "o_collisions": 0, "runtime": 136.11234825570136}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-082"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.578125, "avg_agents_density": 0.07142302925098051, "a_collisions": 189, "o_collisions": 0, "runtime": 151.98676173761487}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-083"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9375, "avg_agents_density": 0.07941982840170193, "a_collisions": 188, "o_collisions": 0, "runtime": 112.78957827854902}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-084"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.99609375, "avg_agents_density": 0.09370439116079211, "a_collisions": 316, "o_collisions": 0, "runtime": 149.2898043161258}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-085"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3125, "avg_agents_density": 0.07264088189924736, "a_collisions": 199, "o_collisions": 0, "runtime": 145.7665007552132}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-086"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.73828125, "avg_agents_density": 0.10797736437254671, "a_collisions": 295, "o_collisions": 0, "runtime": 144.0684171775356}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-087"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.81640625, "avg_agents_density": 0.09803468582240173, "a_collisions": 405, "o_collisions": 0, "runtime": 146.87080389913172}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-088"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3046875, "avg_agents_density": 0.0907705371125576, "a_collisions": 209, "o_collisions": 0, "runtime": 138.40208936482668}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-089"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.10546875, "avg_agents_density": 0.09363712028132858, "a_collisions": 198, "o_collisions": 0, "runtime": 143.69988300465047}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-090"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3359375, "avg_agents_density": 0.09536897133333404, "a_collisions": 164, "o_collisions": 0, "runtime": 138.03828907571733}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-091"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.51953125, "avg_agents_density": 0.07183358079355467, "a_collisions": 182, "o_collisions": 0, "runtime": 151.62594758160412}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-092"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.10546875, "avg_agents_density": 0.08864861585202753, "a_collisions": 212, "o_collisions": 0, "runtime": 134.89177217241377}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-093"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.05859375, "avg_agents_density": 0.09918937397191772, "a_collisions": 204, "o_collisions": 0, "runtime": 138.72219810914248}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-094"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.05859375, "avg_agents_density": 0.10162585217504154, "a_collisions": 259, "o_collisions": 0, "runtime": 139.05545475054532}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-095"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1015625, "avg_agents_density": 0.09374575472630278, "a_collisions": 285, "o_collisions": 0, "runtime": 136.56827300228179}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-096"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.203125, "avg_agents_density": 0.0836713850856332, "a_collisions": 181, "o_collisions": 0, "runtime": 138.14973928313702}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-097"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0, "avg_agents_density": 0.09518551224007506, "a_collisions": 269, "o_collisions": 0, "runtime": 141.28127970080823}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-098"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.15625, "avg_agents_density": 0.09084362086568566, "a_collisions": 225, "o_collisions": 0, "runtime": 145.66810478176922}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-099"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.26953125, "avg_agents_density": 0.08904625233866276, "a_collisions": 177, "o_collisions": 0, "runtime": 138.47773467563093}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-100"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.21484375, "avg_agents_density": 0.09062198108773899, "a_collisions": 231, "o_collisions": 0, "runtime": 141.2267520222813}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-101"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.30859375, "avg_agents_density": 0.10227050512152665, "a_collisions": 244, "o_collisions": 0, "runtime": 157.29949060454965}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-102"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.21484375, "avg_agents_density": 0.08378610159680323, "a_collisions": 298, "o_collisions": 0, "runtime": 160.91192089952528}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-103"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0703125, "avg_agents_density": 0.09744151751665263, "a_collisions": 209, "o_collisions": 0, "runtime": 140.21023853402585}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-104"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7890625, "avg_agents_density": 0.07151033298846342, "a_collisions": 300, "o_collisions": 0, "runtime": 128.56385773140937}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-105"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.6953125, "avg_agents_density": 0.07115244320277948, "a_collisions": 199, "o_collisions": 0, "runtime": 162.94985250663012}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-106"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.02734375, "avg_agents_density": 0.09756876455793749, "a_collisions": 196, "o_collisions": 0, "runtime": 138.8466409901157}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-107"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1796875, "avg_agents_density": 0.10076825349171023, "a_collisions": 207, "o_collisions": 0, "runtime": 147.2764274198562}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-108"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.07421875, "avg_agents_density": 0.11216796595440495, "a_collisions": 317, "o_collisions": 0, "runtime": 159.2935267901048}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-109"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.07421875, "avg_agents_density": 0.09738878248481862, "a_collisions": 234, "o_collisions": 0, "runtime": 144.51348045188934}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-110"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.63671875, "avg_agents_density": 0.09171251974323509, "a_collisions": 271, "o_collisions": 0, "runtime": 183.0446211528033}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-111"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8125, "avg_agents_density": 0.09934218512271879, "a_collisions": 757, "o_collisions": 0, "runtime": 193.6508435551077}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-112"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.8359375, "avg_agents_density": 0.08378535003061936, "a_collisions": 200, "o_collisions": 0, "runtime": 179.71249687112868}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-113"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.62109375, "avg_agents_density": 0.0887736248485811, "a_collisions": 194, "o_collisions": 0, "runtime": 168.01663529872894}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-114"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.12109375, "avg_agents_density": 0.08447853074154621, "a_collisions": 215, "o_collisions": 0, "runtime": 133.58599344920367}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-115"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2890625, "avg_agents_density": 0.11075964231294777, "a_collisions": 265, "o_collisions": 0, "runtime": 154.68484442215413}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-116"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.484375, "avg_agents_density": 0.09026696781762379, "a_collisions": 225, "o_collisions": 0, "runtime": 161.0155060729012}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-117"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0703125, "avg_agents_density": 0.09000958379004234, "a_collisions": 174, "o_collisions": 0, "runtime": 131.16250975895673}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-118"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.98046875, "avg_agents_density": 0.0902030541597508, "a_collisions": 259, "o_collisions": 0, "runtime": 138.60637930966914}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-119"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4609375, "avg_agents_density": 0.06401670223608456, "a_collisions": 153, "o_collisions": 0, "runtime": 138.60843592789024}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-120"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.34765625, "avg_agents_density": 0.09656026902821162, "a_collisions": 227, "o_collisions": 0, "runtime": 152.64161639660597}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-121"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.34765625, "avg_agents_density": 0.07104604509049518, "a_collisions": 190, "o_collisions": 0, "runtime": 144.28932526521385}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-122"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.44921875, "avg_agents_density": 0.08887918854923202, "a_collisions": 326, "o_collisions": 0, "runtime": 208.70391681883484}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-123"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.68359375, "avg_agents_density": 0.10355138730786297, "a_collisions": 346, "o_collisions": 0, "runtime": 155.02265282906592}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-124"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.15625, "avg_agents_density": 0.09046346164984596, "a_collisions": 224, "o_collisions": 0, "runtime": 140.2015397651121}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-125"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.85546875, "avg_agents_density": 0.08098866799462778, "a_collisions": 310, "o_collisions": 0, "runtime": 151.42605495266616}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-126"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.46484375, "avg_agents_density": 0.09067011629666644, "a_collisions": 259, "o_collisions": 0, "runtime": 164.44430704042315}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-127"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.35546875, "avg_agents_density": 0.11399490315583928, "a_collisions": 402, "o_collisions": 0, "runtime": 223.36470111180097}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.5, "avg_agents_density": 0.1340566205575315, "a_collisions": 475, "o_collisions": 0, "runtime": 253.00795536395162}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.54296875, "avg_agents_density": 0.10333705241114774, "a_collisions": 360, "o_collisions": 0, "runtime": 216.76351439859718}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.58984375, "avg_agents_density": 0.1155843082274316, "a_collisions": 464, "o_collisions": 0, "runtime": 239.76116927806288}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.16796875, "avg_agents_density": 0.10486026892582324, "a_collisions": 503, "o_collisions": 0, "runtime": 258.82715309690684}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.02734375, "avg_agents_density": 0.11109860411867889, "a_collisions": 357, "o_collisions": 0, "runtime": 202.1451714411378}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.05078125, "avg_agents_density": 0.12510695373375416, "a_collisions": 681, "o_collisions": 0, "runtime": 267.89620509184897}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0, "avg_agents_density": 0.11796442076066424, "a_collisions": 467, "o_collisions": 0, "runtime": 215.15296490862966}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.30078125, "avg_agents_density": 0.1400608615547184, "a_collisions": 582, "o_collisions": 0, "runtime": 259.8423818014562}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.59765625, "avg_agents_density": 0.1240433727400074, "a_collisions": 455, "o_collisions": 0, "runtime": 252.02762382570654}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.17578125, "avg_agents_density": 0.10226912650096082, "a_collisions": 491, "o_collisions": 0, "runtime": 282.5089972745627}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.92578125, "avg_agents_density": 0.14882445542688466, "a_collisions": 976, "o_collisions": 0, "runtime": 277.33196607325226}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.54296875, "avg_agents_density": 0.12316323308093231, "a_collisions": 472, "o_collisions": 0, "runtime": 232.42608871869743}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.6640625, "avg_agents_density": 0.1136468757301655, "a_collisions": 339, "o_collisions": 0, "runtime": 224.42910194396973}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.546875, "avg_agents_density": 0.13127265127737503, "a_collisions": 470, "o_collisions": 0, "runtime": 245.91387780569494}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.296875, "avg_agents_density": 0.12107336551938602, "a_collisions": 460, "o_collisions": 0, "runtime": 228.48510100040585}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2578125, "avg_agents_density": 0.10803383270995853, "a_collisions": 602, "o_collisions": 0, "runtime": 225.35233304928988}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.42578125, "avg_agents_density": 0.10370522453789531, "a_collisions": 586, "o_collisions": 0, "runtime": 249.2320504207164}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.01171875, "avg_agents_density": 0.11517192488521556, "a_collisions": 456, "o_collisions": 0, "runtime": 213.6215133164078}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.92578125, "avg_agents_density": 0.11246271328754952, "a_collisions": 748, "o_collisions": 0, "runtime": 204.71934290975332}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.15234375, "avg_agents_density": 0.10248534742558817, "a_collisions": 397, "o_collisions": 0, "runtime": 205.5694197434932}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.265625, "avg_agents_density": 0.11711480088055085, "a_collisions": 507, "o_collisions": 0, "runtime": 226.6658722879365}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.56640625, "avg_agents_density": 0.09398055716413711, "a_collisions": 433, "o_collisions": 0, "runtime": 252.2944311229512}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.20703125, "avg_agents_density": 0.14707063414931956, "a_collisions": 876, "o_collisions": 0, "runtime": 321.0832615727559}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09375, "avg_agents_density": 0.10697045188692955, "a_collisions": 490, "o_collisions": 0, "runtime": 235.57850962970406}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.4609375, "avg_agents_density": 0.09864196087194599, "a_collisions": 337, "o_collisions": 0, "runtime": 293.7139745755121}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4375, "avg_agents_density": 0.1034581028239154, "a_collisions": 438, "o_collisions": 0, "runtime": 226.33007734455168}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.15625, "avg_agents_density": 0.09352337217300999, "a_collisions": 546, "o_collisions": 0, "runtime": 231.47772368509322}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9375, "avg_agents_density": 0.10655002315477666, "a_collisions": 1010, "o_collisions": 0, "runtime": 219.61801424622536}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.45703125, "avg_agents_density": 0.12839679606845728, "a_collisions": 504, "o_collisions": 0, "runtime": 236.34455982409418}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.60546875, "avg_agents_density": 0.12250724463771602, "a_collisions": 371, "o_collisions": 0, "runtime": 238.55621855985373}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.91796875, "avg_agents_density": 0.11280623467860802, "a_collisions": 552, "o_collisions": 0, "runtime": 323.6882290095091}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.20703125, "avg_agents_density": 0.10971808318332982, "a_collisions": 592, "o_collisions": 0, "runtime": 245.89160321466625}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-032"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.07421875, "avg_agents_density": 0.1312328721500413, "a_collisions": 526, "o_collisions": 0, "runtime": 221.0056840684265}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-033"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.6171875, "avg_agents_density": 0.13978967919702312, "a_collisions": 480, "o_collisions": 0, "runtime": 254.33473029453307}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-034"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.34375, "avg_agents_density": 0.12524079063009583, "a_collisions": 621, "o_collisions": 0, "runtime": 302.1447111237794}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-035"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.42578125, "avg_agents_density": 0.12044295077728678, "a_collisions": 527, "o_collisions": 0, "runtime": 253.40466242842376}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-036"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.265625, "avg_agents_density": 0.12294666073549482, "a_collisions": 578, "o_collisions": 0, "runtime": 243.21447224263102}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-037"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.36328125, "avg_agents_density": 0.10567618490879357, "a_collisions": 548, "o_collisions": 0, "runtime": 248.52738102339208}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-038"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.98828125, "avg_agents_density": 0.13043066345864537, "a_collisions": 763, "o_collisions": 0, "runtime": 283.0976705485955}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-039"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.87890625, "avg_agents_density": 0.13976039103816604, "a_collisions": 630, "o_collisions": 0, "runtime": 250.86331380531192}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-040"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7890625, "avg_agents_density": 0.10826084904264988, "a_collisions": 1073, "o_collisions": 0, "runtime": 216.61341281980276}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-041"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4765625, "avg_agents_density": 0.12048651587799454, "a_collisions": 438, "o_collisions": 0, "runtime": 250.89446899481118}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-042"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.03125, "avg_agents_density": 0.09245766759497132, "a_collisions": 383, "o_collisions": 0, "runtime": 266.247631104663}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-043"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.546875, "avg_agents_density": 0.09951401147832964, "a_collisions": 382, "o_collisions": 0, "runtime": 236.1815053690225}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-044"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.01171875, "avg_agents_density": 0.11727600039226295, "a_collisions": 660, "o_collisions": 0, "runtime": 214.5203767484054}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-045"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.85546875, "avg_agents_density": 0.08868860218905177, "a_collisions": 372, "o_collisions": 0, "runtime": 250.9765785075724}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-046"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1484375, "avg_agents_density": 0.1275138545591933, "a_collisions": 602, "o_collisions": 0, "runtime": 248.22263339161873}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-047"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.22265625, "avg_agents_density": 0.1216120497516563, "a_collisions": 703, "o_collisions": 0, "runtime": 290.8940587565303}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-048"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.58984375, "avg_agents_density": 0.13323116503128182, "a_collisions": 497, "o_collisions": 0, "runtime": 249.78962265793234}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-049"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1484375, "avg_agents_density": 0.10835991306497549, "a_collisions": 443, "o_collisions": 0, "runtime": 213.33216482494026}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-050"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.46484375, "avg_agents_density": 0.10908520416852023, "a_collisions": 406, "o_collisions": 0, "runtime": 232.5351635105908}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-051"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.25390625, "avg_agents_density": 0.10280416640601893, "a_collisions": 376, "o_collisions": 0, "runtime": 205.14235370978713}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-052"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6484375, "avg_agents_density": 0.1445493224550088, "a_collisions": 820, "o_collisions": 0, "runtime": 244.95004012435675}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-053"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.95703125, "avg_agents_density": 0.09970306806602472, "a_collisions": 1030, "o_collisions": 0, "runtime": 279.88543867412955}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-054"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4296875, "avg_agents_density": 0.11457544654595513, "a_collisions": 403, "o_collisions": 0, "runtime": 236.32822950650007}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-055"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.03515625, "avg_agents_density": 0.08300499152127996, "a_collisions": 257, "o_collisions": 0, "runtime": 250.67231166735291}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-056"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.140625, "avg_agents_density": 0.13454867877451362, "a_collisions": 673, "o_collisions": 0, "runtime": 268.63497171830386}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-057"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.49609375, "avg_agents_density": 0.14795850913694245, "a_collisions": 1475, "o_collisions": 0, "runtime": 283.8058652309701}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-058"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.05078125, "avg_agents_density": 0.11004948265724061, "a_collisions": 503, "o_collisions": 0, "runtime": 227.23242242913693}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-059"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.36328125, "avg_agents_density": 0.0993025640075879, "a_collisions": 332, "o_collisions": 0, "runtime": 292.7721914993599}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-060"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1875, "avg_agents_density": 0.1314999564585863, "a_collisions": 486, "o_collisions": 0, "runtime": 229.4304543705657}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-061"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9140625, "avg_agents_density": 0.11822019203788854, "a_collisions": 615, "o_collisions": 0, "runtime": 266.9220002759248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-062"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.73046875, "avg_agents_density": 0.10810463843707797, "a_collisions": 1023, "o_collisions": 0, "runtime": 262.6877803215757}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-063"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.39453125, "avg_agents_density": 0.1285646005002035, "a_collisions": 394, "o_collisions": 0, "runtime": 225.53023076523095}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-064"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.10546875, "avg_agents_density": 0.14238070178080858, "a_collisions": 843, "o_collisions": 0, "runtime": 264.0980661343783}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-065"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.21875, "avg_agents_density": 0.10230325683934113, "a_collisions": 403, "o_collisions": 0, "runtime": 211.4432700658217}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-066"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.76171875, "avg_agents_density": 0.09261648527451269, "a_collisions": 334, "o_collisions": 0, "runtime": 226.63066199515015}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-067"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.296875, "avg_agents_density": 0.1238786908711133, "a_collisions": 463, "o_collisions": 0, "runtime": 217.65065878350288}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-068"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.67578125, "avg_agents_density": 0.18176230609824778, "a_collisions": 1530, "o_collisions": 0, "runtime": 337.6556286951527}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-069"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1640625, "avg_agents_density": 0.10531676396372958, "a_collisions": 421, "o_collisions": 0, "runtime": 201.2948646163568}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-070"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1484375, "avg_agents_density": 0.12101483898846103, "a_collisions": 632, "o_collisions": 0, "runtime": 238.35282639600337}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-071"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.12109375, "avg_agents_density": 0.0772656285249258, "a_collisions": 252, "o_collisions": 0, "runtime": 239.48538416065276}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-072"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.56640625, "avg_agents_density": 0.11915784624936353, "a_collisions": 430, "o_collisions": 0, "runtime": 229.43681031372398}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-073"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.14453125, "avg_agents_density": 0.09316496330030564, "a_collisions": 522, "o_collisions": 0, "runtime": 232.2306505534798}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-074"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.74609375, "avg_agents_density": 0.08109917628603837, "a_collisions": 324, "o_collisions": 0, "runtime": 222.0684443851933}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-075"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09765625, "avg_agents_density": 0.11768493639940608, "a_collisions": 461, "o_collisions": 0, "runtime": 227.0010961489752}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-076"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.71875, "avg_agents_density": 0.12141490934857424, "a_collisions": 993, "o_collisions": 0, "runtime": 244.13485155254602}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-077"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.5234375, "avg_agents_density": 0.12681565861483135, "a_collisions": 419, "o_collisions": 0, "runtime": 233.49678039364517}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-078"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.89453125, "avg_agents_density": 0.09899001126875474, "a_collisions": 437, "o_collisions": 0, "runtime": 279.76525773480535}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-079"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.140625, "avg_agents_density": 0.07965196443025677, "a_collisions": 265, "o_collisions": 0, "runtime": 240.58115901239216}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-080"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4609375, "avg_agents_density": 0.11049531994413458, "a_collisions": 567, "o_collisions": 0, "runtime": 276.12506536673754}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-081"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.984375, "avg_agents_density": 0.11816164118402306, "a_collisions": 536, "o_collisions": 0, "runtime": 214.25591977871954}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-082"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.0, "avg_agents_density": 0.09282035006244617, "a_collisions": 346, "o_collisions": 0, "runtime": 259.71028856839985}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-083"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.00390625, "avg_agents_density": 0.10054186611697534, "a_collisions": 518, "o_collisions": 0, "runtime": 197.74153428152204}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-084"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.93359375, "avg_agents_density": 0.13457158900998198, "a_collisions": 738, "o_collisions": 0, "runtime": 255.03147353138775}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-085"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.67578125, "avg_agents_density": 0.0950723525153624, "a_collisions": 357, "o_collisions": 0, "runtime": 230.95572406519204}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-086"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.87109375, "avg_agents_density": 0.12115195068256888, "a_collisions": 468, "o_collisions": 0, "runtime": 215.45595457497984}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-087"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.78515625, "avg_agents_density": 0.13524318055797502, "a_collisions": 1605, "o_collisions": 0, "runtime": 238.49378019291908}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-088"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.546875, "avg_agents_density": 0.12181288716274577, "a_collisions": 389, "o_collisions": 0, "runtime": 231.36114989966154}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-089"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.33984375, "avg_agents_density": 0.1284539166584303, "a_collisions": 446, "o_collisions": 0, "runtime": 235.8925708727911}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-090"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.5078125, "avg_agents_density": 0.12546096823170994, "a_collisions": 373, "o_collisions": 0, "runtime": 227.0210453690961}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-091"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.95703125, "avg_agents_density": 0.09134389414523328, "a_collisions": 332, "o_collisions": 0, "runtime": 253.28596543893218}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-092"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2890625, "avg_agents_density": 0.11653734015097922, "a_collisions": 378, "o_collisions": 0, "runtime": 208.7807008139789}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-093"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1171875, "avg_agents_density": 0.1381543997660511, "a_collisions": 644, "o_collisions": 0, "runtime": 232.06275270693004}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-094"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.140625, "avg_agents_density": 0.13659517358069148, "a_collisions": 663, "o_collisions": 0, "runtime": 229.46771969180554}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-095"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.32421875, "avg_agents_density": 0.11710795137986037, "a_collisions": 356, "o_collisions": 0, "runtime": 210.27705225534737}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-096"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3203125, "avg_agents_density": 0.10737185041763571, "a_collisions": 444, "o_collisions": 0, "runtime": 218.8717968231067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-097"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.078125, "avg_agents_density": 0.1266527062749291, "a_collisions": 497, "o_collisions": 0, "runtime": 226.2176171867177}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-098"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.39453125, "avg_agents_density": 0.12077798021174393, "a_collisions": 409, "o_collisions": 0, "runtime": 227.4032128509134}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-099"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.52734375, "avg_agents_density": 0.1170353220721398, "a_collisions": 381, "o_collisions": 0, "runtime": 225.35865042358637}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-100"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.44140625, "avg_agents_density": 0.11798115850894528, "a_collisions": 407, "o_collisions": 0, "runtime": 230.86836768314242}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-101"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.57421875, "avg_agents_density": 0.1328928708475561, "a_collisions": 483, "o_collisions": 0, "runtime": 247.82227857783437}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-102"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.328125, "avg_agents_density": 0.10590389398545569, "a_collisions": 628, "o_collisions": 0, "runtime": 257.103250595741}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-103"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.23046875, "avg_agents_density": 0.12547237637936667, "a_collisions": 495, "o_collisions": 0, "runtime": 224.95246137399226}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-104"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5234375, "avg_agents_density": 0.11638070873329179, "a_collisions": 2482, "o_collisions": 0, "runtime": 297.0863735321909}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-105"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.15234375, "avg_agents_density": 0.09161543333219568, "a_collisions": 318, "o_collisions": 0, "runtime": 267.3580208849162}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-106"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.07421875, "avg_agents_density": 0.12935329155563616, "a_collisions": 488, "o_collisions": 0, "runtime": 234.41595093905926}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-107"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.359375, "avg_agents_density": 0.12898911083092549, "a_collisions": 543, "o_collisions": 0, "runtime": 231.83647797629237}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-108"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.203125, "avg_agents_density": 0.14296570959078667, "a_collisions": 589, "o_collisions": 0, "runtime": 239.590673988685}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-109"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2421875, "avg_agents_density": 0.1225009548002846, "a_collisions": 452, "o_collisions": 0, "runtime": 226.34079931210726}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-110"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.97265625, "avg_agents_density": 0.10938976150294093, "a_collisions": 435, "o_collisions": 0, "runtime": 267.53838698379695}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-111"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.82421875, "avg_agents_density": 0.12158671485921063, "a_collisions": 1338, "o_collisions": 0, "runtime": 282.4240708965808}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-112"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.28125, "avg_agents_density": 0.1073952389647577, "a_collisions": 375, "o_collisions": 0, "runtime": 290.8594791619107}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-113"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.95703125, "avg_agents_density": 0.1125767628119109, "a_collisions": 391, "o_collisions": 0, "runtime": 268.9097371548414}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-114"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.34765625, "avg_agents_density": 0.10154389796433369, "a_collisions": 325, "o_collisions": 0, "runtime": 201.40679719951004}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-115"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.29296875, "avg_agents_density": 0.1423403093807958, "a_collisions": 904, "o_collisions": 0, "runtime": 269.20327863655984}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-116"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.78515625, "avg_agents_density": 0.11547039434483328, "a_collisions": 446, "o_collisions": 0, "runtime": 258.76365824695677}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-117"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.30859375, "avg_agents_density": 0.11421863444102251, "a_collisions": 372, "o_collisions": 0, "runtime": 199.62632015626878}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-118"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.078125, "avg_agents_density": 0.11146470087364203, "a_collisions": 528, "o_collisions": 0, "runtime": 222.30765714403242}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-119"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.79296875, "avg_agents_density": 0.08010923351596377, "a_collisions": 273, "o_collisions": 0, "runtime": 225.51395433582366}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-120"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.62890625, "avg_agents_density": 0.12175457846659904, "a_collisions": 432, "o_collisions": 0, "runtime": 241.32709798030555}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-121"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.65625, "avg_agents_density": 0.09000324546018777, "a_collisions": 348, "o_collisions": 0, "runtime": 225.5687255077064}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-122"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.7890625, "avg_agents_density": 0.11341780753421524, "a_collisions": 640, "o_collisions": 0, "runtime": 335.2459844900295}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-123"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6953125, "avg_agents_density": 0.14468372310535974, "a_collisions": 847, "o_collisions": 0, "runtime": 250.87077351100743}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-124"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.328125, "avg_agents_density": 0.11895384686390002, "a_collisions": 503, "o_collisions": 0, "runtime": 228.75342832598835}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-125"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.60546875, "avg_agents_density": 0.12551662951889822, "a_collisions": 2614, "o_collisions": 0, "runtime": 323.94203953724355}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-126"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.80078125, "avg_agents_density": 0.11581585923523648, "a_collisions": 530, "o_collisions": 0, "runtime": 261.62254728842527}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-127"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.58984375, "avg_agents_density": 0.16672200374269705, "a_collisions": 1086, "o_collisions": 0, "runtime": 439.6951783783734}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.66015625, "avg_agents_density": 0.18553555764241036, "a_collisions": 1246, "o_collisions": 0, "runtime": 475.0571584915742}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.7578125, "avg_agents_density": 0.1603748128380579, "a_collisions": 1136, "o_collisions": 0, "runtime": 446.50868846289814}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.609375, "avg_agents_density": 0.17663173779244495, "a_collisions": 1434, "o_collisions": 0, "runtime": 509.75266814325005}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.29296875, "avg_agents_density": 0.16314895197340332, "a_collisions": 1628, "o_collisions": 0, "runtime": 564.7637486523017}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.99609375, "avg_agents_density": 0.16224675297654356, "a_collisions": 1616, "o_collisions": 0, "runtime": 421.26898242812604}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.14453125, "avg_agents_density": 0.17988839697652353, "a_collisions": 1565, "o_collisions": 0, "runtime": 518.9545460548252}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0, "avg_agents_density": 0.1842390943169918, "a_collisions": 1361, "o_collisions": 0, "runtime": 420.9973338302225}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.42578125, "avg_agents_density": 0.18919183645753443, "a_collisions": 1457, "o_collisions": 0, "runtime": 496.948540084064}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.96875, "avg_agents_density": 0.1774911987656787, "a_collisions": 1140, "o_collisions": 0, "runtime": 499.5715625016019}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3046875, "avg_agents_density": 0.17654538333628356, "a_collisions": 1961, "o_collisions": 0, "runtime": 709.433481644839}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.859375, "avg_agents_density": 0.21240696986117627, "a_collisions": 3492, "o_collisions": 0, "runtime": 599.520321204327}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.76171875, "avg_agents_density": 0.17843545338076794, "a_collisions": 1179, "o_collisions": 0, "runtime": 466.0878582689911}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.0703125, "avg_agents_density": 0.1619937381033346, "a_collisions": 890, "o_collisions": 0, "runtime": 435.93309546727687}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.75, "avg_agents_density": 0.19745084845582192, "a_collisions": 1289, "o_collisions": 0, "runtime": 521.1366628035903}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3203125, "avg_agents_density": 0.21369182213277702, "a_collisions": 1726, "o_collisions": 0, "runtime": 512.1087947376072}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.41796875, "avg_agents_density": 0.16031833931666384, "a_collisions": 1375, "o_collisions": 0, "runtime": 460.67579622752964}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.91015625, "avg_agents_density": 0.13995203226252778, "a_collisions": 1068, "o_collisions": 0, "runtime": 457.96402506902814}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0703125, "avg_agents_density": 0.16569345681566747, "a_collisions": 1690, "o_collisions": 0, "runtime": 423.6258322270587}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7578125, "avg_agents_density": 0.19457612455353065, "a_collisions": 4258, "o_collisions": 0, "runtime": 560.8134427806363}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.17578125, "avg_agents_density": 0.15472181019655895, "a_collisions": 1898, "o_collisions": 0, "runtime": 406.54256082791835}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.390625, "avg_agents_density": 0.1635469849722166, "a_collisions": 1461, "o_collisions": 0, "runtime": 453.8849296234548}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.73828125, "avg_agents_density": 0.14545016153718016, "a_collisions": 1245, "o_collisions": 0, "runtime": 537.6682218909264}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.33984375, "avg_agents_density": 0.18285210967726814, "a_collisions": 1635, "o_collisions": 0, "runtime": 556.7358992593363}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.33984375, "avg_agents_density": 0.15310890563585342, "a_collisions": 1358, "o_collisions": 0, "runtime": 486.747454081662}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.3984375, "avg_agents_density": 0.14559675158896154, "a_collisions": 839, "o_collisions": 0, "runtime": 610.9892178997397}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.88671875, "avg_agents_density": 0.1386329605541339, "a_collisions": 1039, "o_collisions": 0, "runtime": 437.111370514147}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.015625, "avg_agents_density": 0.14237140121336556, "a_collisions": 2742, "o_collisions": 0, "runtime": 539.6141241854057}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.01171875, "avg_agents_density": 0.17947083919981088, "a_collisions": 1616, "o_collisions": 0, "runtime": 466.27303943317384}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.53515625, "avg_agents_density": 0.18821706834120425, "a_collisions": 1216, "o_collisions": 0, "runtime": 467.72240819968283}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.61328125, "avg_agents_density": 0.17316252137485377, "a_collisions": 2079, "o_collisions": 0, "runtime": 515.0424942774698}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.328125, "avg_agents_density": 0.17676603777601688, "a_collisions": 1516, "o_collisions": 0, "runtime": 724.7487034499645}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.17578125, "avg_agents_density": 0.18334936961796314, "a_collisions": 3029, "o_collisions": 0, "runtime": 736.3010013317689}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-032"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1015625, "avg_agents_density": 0.18789247532356876, "a_collisions": 1795, "o_collisions": 0, "runtime": 430.4242041874677}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-033"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.67578125, "avg_agents_density": 0.20141806504076715, "a_collisions": 1454, "o_collisions": 0, "runtime": 519.0978179033846}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-034"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3203125, "avg_agents_density": 0.19555422436814007, "a_collisions": 2593, "o_collisions": 0, "runtime": 650.3511399952695}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-035"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3671875, "avg_agents_density": 0.20380407473530815, "a_collisions": 1787, "o_collisions": 0, "runtime": 550.0390826743096}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-036"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.953125, "avg_agents_density": 0.1859067330648092, "a_collisions": 3930, "o_collisions": 0, "runtime": 611.4638816965744}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-037"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.60546875, "avg_agents_density": 0.152161756159462, "a_collisions": 1232, "o_collisions": 0, "runtime": 505.6644521979615}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-038"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.91796875, "avg_agents_density": 0.1929193633816649, "a_collisions": 2025, "o_collisions": 0, "runtime": 545.7830700371414}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-039"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.01171875, "avg_agents_density": 0.1824044603776796, "a_collisions": 1470, "o_collisions": 0, "runtime": 446.09583961684257}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-040"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.859375, "avg_agents_density": 0.16196287553675642, "a_collisions": 2365, "o_collisions": 0, "runtime": 449.23323733266443}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-041"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.66796875, "avg_agents_density": 0.1904827834033277, "a_collisions": 1437, "o_collisions": 0, "runtime": 586.4073309320956}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-042"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.8046875, "avg_agents_density": 0.13157971810155, "a_collisions": 821, "o_collisions": 0, "runtime": 541.9466200778261}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-043"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.8203125, "avg_agents_density": 0.13538335183683584, "a_collisions": 1112, "o_collisions": 0, "runtime": 470.98865894414485}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-044"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.140625, "avg_agents_density": 0.16564454050387026, "a_collisions": 2029, "o_collisions": 0, "runtime": 421.4197808019817}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-045"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.359375, "avg_agents_density": 0.13427191394068774, "a_collisions": 984, "o_collisions": 0, "runtime": 521.9736984353513}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-046"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0859375, "avg_agents_density": 0.19268093470917014, "a_collisions": 2621, "o_collisions": 0, "runtime": 511.6115686511621}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-047"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.2578125, "avg_agents_density": 0.20477967618066886, "a_collisions": 2502, "o_collisions": 0, "runtime": 733.953427920118}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-048"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.7109375, "avg_agents_density": 0.2006887717419654, "a_collisions": 1386, "o_collisions": 0, "runtime": 516.7684171227738}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-049"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.25, "avg_agents_density": 0.14744573846219838, "a_collisions": 1108, "o_collisions": 0, "runtime": 438.38269699458033}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-050"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.53125, "avg_agents_density": 0.16724372310464536, "a_collisions": 1457, "o_collisions": 0, "runtime": 508.92904131114483}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-051"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3984375, "avg_agents_density": 0.1462757555054072, "a_collisions": 1243, "o_collisions": 0, "runtime": 410.96622218657285}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-052"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.43359375, "avg_agents_density": 0.23713580573221335, "a_collisions": 4162, "o_collisions": 0, "runtime": 545.2439528787509}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-053"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.953125, "avg_agents_density": 0.18014185180241213, "a_collisions": 4166, "o_collisions": 0, "runtime": 773.6580725545064}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-054"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.359375, "avg_agents_density": 0.18934243205153603, "a_collisions": 1559, "o_collisions": 0, "runtime": 513.3607873804867}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-055"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.65625, "avg_agents_density": 0.1212095577784493, "a_collisions": 821, "o_collisions": 0, "runtime": 519.474029712379}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-056"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.82421875, "avg_agents_density": 0.2496553945680236, "a_collisions": 3708, "o_collisions": 0, "runtime": 703.3425749205053}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-057"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.2734375, "avg_agents_density": 0.2916895476063321, "a_collisions": 5464, "o_collisions": 0, "runtime": 658.8033748911694}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-058"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.13671875, "avg_agents_density": 0.16017752931185425, "a_collisions": 1742, "o_collisions": 0, "runtime": 487.53870152216405}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-059"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.28125, "avg_agents_density": 0.14489986955074433, "a_collisions": 792, "o_collisions": 0, "runtime": 594.2438269862905}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-060"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.125, "avg_agents_density": 0.18142444909420455, "a_collisions": 2181, "o_collisions": 0, "runtime": 460.75764429196715}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-061"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0234375, "avg_agents_density": 0.18023069620441987, "a_collisions": 2087, "o_collisions": 0, "runtime": 577.6538372989744}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-062"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.41015625, "avg_agents_density": 0.2215523359042202, "a_collisions": 5794, "o_collisions": 0, "runtime": 678.2919445894659}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-063"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.72265625, "avg_agents_density": 0.1645602228408923, "a_collisions": 886, "o_collisions": 0, "runtime": 396.9503961922601}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-064"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.828125, "avg_agents_density": 0.24955219315915114, "a_collisions": 4527, "o_collisions": 0, "runtime": 626.0546170147136}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-065"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.31640625, "avg_agents_density": 0.17236306551924674, "a_collisions": 1356, "o_collisions": 0, "runtime": 482.88552884571254}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-066"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.23828125, "avg_agents_density": 0.13196127626172205, "a_collisions": 855, "o_collisions": 0, "runtime": 461.7247497206554}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-067"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3984375, "avg_agents_density": 0.166256700136507, "a_collisions": 1280, "o_collisions": 0, "runtime": 415.5123625919223}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-068"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.41015625, "avg_agents_density": 0.26653767342104917, "a_collisions": 5632, "o_collisions": 0, "runtime": 727.7291856845841}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-069"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.890625, "avg_agents_density": 0.1831994226993905, "a_collisions": 3967, "o_collisions": 0, "runtime": 570.9504053536803}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-070"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09375, "avg_agents_density": 0.18405798710391189, "a_collisions": 1633, "o_collisions": 0, "runtime": 479.36362723633647}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-071"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.07421875, "avg_agents_density": 0.11112468279628189, "a_collisions": 604, "o_collisions": 0, "runtime": 482.33005776721984}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-072"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.88671875, "avg_agents_density": 0.18446339826895092, "a_collisions": 1135, "o_collisions": 0, "runtime": 480.19766966905445}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-073"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.078125, "avg_agents_density": 0.15015787410843714, "a_collisions": 2801, "o_collisions": 0, "runtime": 569.0675322562456}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-074"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.1015625, "avg_agents_density": 0.12061695337943333, "a_collisions": 1268, "o_collisions": 0, "runtime": 467.92486528120935}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-075"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09375, "avg_agents_density": 0.1849057978106316, "a_collisions": 2402, "o_collisions": 0, "runtime": 514.5593228060752}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-076"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7578125, "avg_agents_density": 0.1937078414660094, "a_collisions": 3893, "o_collisions": 0, "runtime": 515.391987378709}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-077"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.76171875, "avg_agents_density": 0.18805718101290272, "a_collisions": 1120, "o_collisions": 0, "runtime": 462.80110751464963}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-078"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.34375, "avg_agents_density": 0.14482347684282357, "a_collisions": 1291, "o_collisions": 0, "runtime": 599.4241942875087}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-079"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.03125, "avg_agents_density": 0.11539272802749431, "a_collisions": 633, "o_collisions": 0, "runtime": 486.92088200431317}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-080"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.58203125, "avg_agents_density": 0.16619959045260913, "a_collisions": 1507, "o_collisions": 0, "runtime": 576.5140219908208}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-081"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.98828125, "avg_agents_density": 0.1622768725195499, "a_collisions": 1369, "o_collisions": 0, "runtime": 426.51948023214936}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-082"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.8203125, "avg_agents_density": 0.1322653534494935, "a_collisions": 840, "o_collisions": 0, "runtime": 518.9394263643771}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-083"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.15234375, "avg_agents_density": 0.14162798868221863, "a_collisions": 2018, "o_collisions": 0, "runtime": 419.60781507380307}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-084"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.01171875, "avg_agents_density": 0.17071501267451913, "a_collisions": 2680, "o_collisions": 0, "runtime": 444.30957077257335}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-085"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.16015625, "avg_agents_density": 0.1409079798216307, "a_collisions": 956, "o_collisions": 0, "runtime": 483.3944452730939}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-086"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.84765625, "avg_agents_density": 0.17324593004792732, "a_collisions": 1830, "o_collisions": 0, "runtime": 446.97420279029757}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-087"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.578125, "avg_agents_density": 0.23128181735855147, "a_collisions": 5004, "o_collisions": 0, "runtime": 608.7163179777563}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-088"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.609375, "avg_agents_density": 0.1856275876390531, "a_collisions": 1372, "o_collisions": 0, "runtime": 482.7863349886611}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-089"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.46484375, "avg_agents_density": 0.17532627864063496, "a_collisions": 1234, "o_collisions": 0, "runtime": 444.19076585769653}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-090"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.69921875, "avg_agents_density": 0.19024924451676367, "a_collisions": 1213, "o_collisions": 0, "runtime": 480.127990366891}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-091"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.6640625, "avg_agents_density": 0.13270405957319292, "a_collisions": 899, "o_collisions": 0, "runtime": 522.6404408579692}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-092"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3359375, "avg_agents_density": 0.18075648958248838, "a_collisions": 1271, "o_collisions": 0, "runtime": 416.42801733408123}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-093"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09765625, "avg_agents_density": 0.18660450538300982, "a_collisions": 1888, "o_collisions": 0, "runtime": 474.8335672598332}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-094"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.296875, "avg_agents_density": 0.18244548042390266, "a_collisions": 1239, "o_collisions": 0, "runtime": 404.6885878518224}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-095"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.5234375, "avg_agents_density": 0.18340619380539533, "a_collisions": 1220, "o_collisions": 0, "runtime": 447.23411018401384}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-096"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3515625, "avg_agents_density": 0.17714498892127545, "a_collisions": 2021, "o_collisions": 0, "runtime": 497.7648642268032}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-097"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.046875, "avg_agents_density": 0.17336929343236213, "a_collisions": 1595, "o_collisions": 0, "runtime": 432.9217170588672}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-098"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.5546875, "avg_agents_density": 0.1730814724532807, "a_collisions": 1141, "o_collisions": 0, "runtime": 452.8932688757777}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-099"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.87890625, "avg_agents_density": 0.17059999989671912, "a_collisions": 1016, "o_collisions": 0, "runtime": 451.72949838172644}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-100"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.6875, "avg_agents_density": 0.16447724479357897, "a_collisions": 1049, "o_collisions": 0, "runtime": 452.71115307323635}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-101"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.70703125, "avg_agents_density": 0.18708485681266385, "a_collisions": 1230, "o_collisions": 0, "runtime": 479.17367156781256}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-102"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.6015625, "avg_agents_density": 0.14991207473055224, "a_collisions": 1711, "o_collisions": 0, "runtime": 559.3933750707656}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-103"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09765625, "avg_agents_density": 0.20025289054485226, "a_collisions": 1844, "o_collisions": 0, "runtime": 521.7765078144148}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-104"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.66015625, "avg_agents_density": 0.15398756983691822, "a_collisions": 4106, "o_collisions": 0, "runtime": 512.0232919137925}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-105"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.05078125, "avg_agents_density": 0.13267644385876406, "a_collisions": 709, "o_collisions": 0, "runtime": 531.3756661685184}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-106"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.07421875, "avg_agents_density": 0.18524859742848, "a_collisions": 1990, "o_collisions": 0, "runtime": 520.3466807221994}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-107"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4453125, "avg_agents_density": 0.18678289038796114, "a_collisions": 1492, "o_collisions": 0, "runtime": 472.42529038805515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-108"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.12109375, "avg_agents_density": 0.200972565836481, "a_collisions": 2028, "o_collisions": 0, "runtime": 489.3316443823278}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-109"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.21484375, "avg_agents_density": 0.1735749150800915, "a_collisions": 1709, "o_collisions": 0, "runtime": 479.01470847800374}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-110"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.5703125, "avg_agents_density": 0.15385735916470974, "a_collisions": 1067, "o_collisions": 0, "runtime": 536.1073260949925}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-111"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.765625, "avg_agents_density": 0.22028530370282423, "a_collisions": 4233, "o_collisions": 0, "runtime": 606.4145685508847}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-112"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.9140625, "avg_agents_density": 0.16090454763490405, "a_collisions": 1008, "o_collisions": 0, "runtime": 608.8154927939177}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-113"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.51953125, "avg_agents_density": 0.17050873468863786, "a_collisions": 1078, "o_collisions": 0, "runtime": 582.5826102662832}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-114"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.24609375, "avg_agents_density": 0.13006143019007496, "a_collisions": 1846, "o_collisions": 0, "runtime": 398.09775898605585}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-115"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0859375, "avg_agents_density": 0.21198335052346662, "a_collisions": 3195, "o_collisions": 0, "runtime": 583.6378439934924}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-116"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.1875, "avg_agents_density": 0.1742001479912017, "a_collisions": 1260, "o_collisions": 0, "runtime": 558.2627308461815}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-117"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3671875, "avg_agents_density": 0.1692983211500775, "a_collisions": 1247, "o_collisions": 0, "runtime": 412.8867152510211}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-118"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.13671875, "avg_agents_density": 0.15524803404268295, "a_collisions": 1577, "o_collisions": 0, "runtime": 447.59294248651713}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-119"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.49609375, "avg_agents_density": 0.1175451007419358, "a_collisions": 770, "o_collisions": 0, "runtime": 453.6624854542315}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-120"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.89453125, "avg_agents_density": 0.18734805831308368, "a_collisions": 1307, "o_collisions": 0, "runtime": 514.505590043962}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-121"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.97265625, "avg_agents_density": 0.13896427663078414, "a_collisions": 1089, "o_collisions": 0, "runtime": 494.8494886131957}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-122"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.0390625, "avg_agents_density": 0.18089018997114417, "a_collisions": 1677, "o_collisions": 0, "runtime": 765.5649849576876}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-123"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.80078125, "avg_agents_density": 0.19677399432205075, "a_collisions": 1975, "o_collisions": 0, "runtime": 457.46179512981325}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-124"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.53125, "avg_agents_density": 0.16959832877038566, "a_collisions": 1265, "o_collisions": 0, "runtime": 442.4894402278587}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-125"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.48828125, "avg_agents_density": 0.20396428456358429, "a_collisions": 5689, "o_collisions": 0, "runtime": 689.8473363080993}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-126"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.21875, "avg_agents_density": 0.16654074241860453, "a_collisions": 1179, "o_collisions": 0, "runtime": 542.0994497435167}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-127"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.54296875, "avg_agents_density": 0.22389868840332924, "a_collisions": 2519, "o_collisions": 0, "runtime": 761.3219461655244}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.54296875, "avg_agents_density": 0.24326471268686292, "a_collisions": 2861, "o_collisions": 0, "runtime": 813.0701039861888}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.80859375, "avg_agents_density": 0.21449286718487115, "a_collisions": 2914, "o_collisions": 0, "runtime": 821.931184980087}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.47265625, "avg_agents_density": 0.2354105468645615, "a_collisions": 3228, "o_collisions": 0, "runtime": 858.6236904207617}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.10546875, "avg_agents_density": 0.2390774422791227, "a_collisions": 5665, "o_collisions": 0, "runtime": 1160.1124380324036}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.97265625, "avg_agents_density": 0.2202977656199414, "a_collisions": 4592, "o_collisions": 0, "runtime": 696.4304333850741}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1875, "avg_agents_density": 0.22556883154160104, "a_collisions": 3755, "o_collisions": 0, "runtime": 969.5286142956465}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.03125, "avg_agents_density": 0.21975076729414608, "a_collisions": 2764, "o_collisions": 0, "runtime": 628.8998593911529}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.22265625, "avg_agents_density": 0.26894612584129435, "a_collisions": 3964, "o_collisions": 0, "runtime": 873.3036891268566}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.78125, "avg_agents_density": 0.23657916439206053, "a_collisions": 2818, "o_collisions": 0, "runtime": 880.2299817204475}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.85546875, "avg_agents_density": 0.2687370171265585, "a_collisions": 6729, "o_collisions": 0, "runtime": 1350.080055047758}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.42578125, "avg_agents_density": 0.3515610638350874, "a_collisions": 8510, "o_collisions": 0, "runtime": 1113.136292384006}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.6171875, "avg_agents_density": 0.24253283062932876, "a_collisions": 2824, "o_collisions": 0, "runtime": 781.652622253634}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.05078125, "avg_agents_density": 0.2185945594284524, "a_collisions": 2078, "o_collisions": 0, "runtime": 750.7966094128788}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.68359375, "avg_agents_density": 0.2510498722547159, "a_collisions": 2699, "o_collisions": 0, "runtime": 864.4559307312593}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.09765625, "avg_agents_density": 0.279092095458511, "a_collisions": 3614, "o_collisions": 0, "runtime": 836.8536031777039}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1640625, "avg_agents_density": 0.2477141245688463, "a_collisions": 4693, "o_collisions": 0, "runtime": 950.0375912385061}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.90625, "avg_agents_density": 0.1939078458365118, "a_collisions": 2417, "o_collisions": 0, "runtime": 800.3978350078687}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.828125, "avg_agents_density": 0.26506731516716847, "a_collisions": 6231, "o_collisions": 0, "runtime": 822.9893391449004}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.52734375, "avg_agents_density": 0.2914852681026426, "a_collisions": 8957, "o_collisions": 0, "runtime": 896.9035564111546}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.19921875, "avg_agents_density": 0.19667166380806891, "a_collisions": 3474, "o_collisions": 0, "runtime": 683.3405566988513}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.18359375, "avg_agents_density": 0.2448878619824962, "a_collisions": 5655, "o_collisions": 0, "runtime": 909.6708741318434}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.76953125, "avg_agents_density": 0.20176185592023418, "a_collisions": 2888, "o_collisions": 0, "runtime": 966.9675159202889}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.05859375, "avg_agents_density": 0.2452386438147695, "a_collisions": 5716, "o_collisions": 0, "runtime": 975.8179327473044}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.21875, "avg_agents_density": 0.20535742241073504, "a_collisions": 3220, "o_collisions": 0, "runtime": 935.7926995279267}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 4.15234375, "avg_agents_density": 0.1926505053234135, "a_collisions": 1696, "o_collisions": 0, "runtime": 1059.1593799553812}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.29296875, "avg_agents_density": 0.255194908412774, "a_collisions": 4978, "o_collisions": 0, "runtime": 973.3549972511828}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.86328125, "avg_agents_density": 0.2200656374616579, "a_collisions": 5846, "o_collisions": 0, "runtime": 911.6008838955313}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8984375, "avg_agents_density": 0.24611172468224676, "a_collisions": 5921, "o_collisions": 0, "runtime": 918.6134009016678}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.23828125, "avg_agents_density": 0.24594498621009092, "a_collisions": 5046, "o_collisions": 0, "runtime": 834.6662644157186}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.59765625, "avg_agents_density": 0.23582284453451124, "a_collisions": 3779, "o_collisions": 0, "runtime": 850.1196733033285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3203125, "avg_agents_density": 0.29045044430595585, "a_collisions": 4805, "o_collisions": 0, "runtime": 1562.1165759759024}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0, "avg_agents_density": 0.24206044637087082, "a_collisions": 6374, "o_collisions": 0, "runtime": 1199.092889125459}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-032"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0390625, "avg_agents_density": 0.24197547045991868, "a_collisions": 4486, "o_collisions": 0, "runtime": 764.7257420821115}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-033"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.453125, "avg_agents_density": 0.27211576739819354, "a_collisions": 3972, "o_collisions": 0, "runtime": 909.6609108773991}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-034"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1640625, "avg_agents_density": 0.27824667055628516, "a_collisions": 5715, "o_collisions": 0, "runtime": 1193.1181214591488}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-035"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.12890625, "avg_agents_density": 0.2639517513614267, "a_collisions": 4804, "o_collisions": 0, "runtime": 918.8730617985129}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-036"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.890625, "avg_agents_density": 0.2584997341531896, "a_collisions": 7499, "o_collisions": 0, "runtime": 1024.307484516874}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-037"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.46875, "avg_agents_density": 0.21824033493222403, "a_collisions": 3336, "o_collisions": 0, "runtime": 949.2307376945391}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-038"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.890625, "avg_agents_density": 0.20391304289815038, "a_collisions": 4809, "o_collisions": 0, "runtime": 857.8762938166037}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-039"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.96875, "avg_agents_density": 0.22099046793123053, "a_collisions": 3667, "o_collisions": 0, "runtime": 728.1119461199269}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-040"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.640625, "avg_agents_density": 0.2517615145637574, "a_collisions": 6727, "o_collisions": 0, "runtime": 807.744435550645}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-041"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.73828125, "avg_agents_density": 0.2318465321062272, "a_collisions": 2622, "o_collisions": 0, "runtime": 924.9553644312546}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-042"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.3359375, "avg_agents_density": 0.1740854230140348, "a_collisions": 1602, "o_collisions": 0, "runtime": 918.338369583711}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-043"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.5546875, "avg_agents_density": 0.22504239275069376, "a_collisions": 5393, "o_collisions": 0, "runtime": 1115.9386716904119}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-044"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.91796875, "avg_agents_density": 0.25160772940137305, "a_collisions": 5815, "o_collisions": 0, "runtime": 751.5912731401622}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-045"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.5625, "avg_agents_density": 0.18424226845221894, "a_collisions": 2285, "o_collisions": 0, "runtime": 946.2954902108759}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-046"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.95703125, "avg_agents_density": 0.2614397649326991, "a_collisions": 5242, "o_collisions": 0, "runtime": 860.8818824347109}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-047"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.44921875, "avg_agents_density": 0.21771348771696047, "a_collisions": 3249, "o_collisions": 0, "runtime": 988.7276810929179}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-048"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.69140625, "avg_agents_density": 0.24330233063485002, "a_collisions": 3001, "o_collisions": 0, "runtime": 840.0903784781694}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-049"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.140625, "avg_agents_density": 0.22630997742970732, "a_collisions": 4008, "o_collisions": 0, "runtime": 993.7201328100637}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-050"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.60546875, "avg_agents_density": 0.2228555408605799, "a_collisions": 2826, "o_collisions": 0, "runtime": 861.1262044692412}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-051"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.35546875, "avg_agents_density": 0.1828172999490575, "a_collisions": 2450, "o_collisions": 0, "runtime": 628.9525253046304}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-052"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.34375, "avg_agents_density": 0.2927007779830359, "a_collisions": 6588, "o_collisions": 0, "runtime": 909.9542412478477}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-053"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.78125, "avg_agents_density": 0.26145689911446807, "a_collisions": 9147, "o_collisions": 0, "runtime": 1250.9396017994732}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-054"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3359375, "avg_agents_density": 0.22193990861367474, "a_collisions": 2831, "o_collisions": 0, "runtime": 763.0941006662324}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-055"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.484375, "avg_agents_density": 0.1591862349147433, "a_collisions": 1451, "o_collisions": 0, "runtime": 878.5536727597937}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-056"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8359375, "avg_agents_density": 0.29181291988608543, "a_collisions": 6057, "o_collisions": 0, "runtime": 1075.5602604271844}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-057"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.13671875, "avg_agents_density": 0.383650737416368, "a_collisions": 10890, "o_collisions": 0, "runtime": 1012.9864994985983}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-058"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.2425761976643019, "a_collisions": 6378, "o_collisions": 0, "runtime": 1010.5849027084187}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-059"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.97265625, "avg_agents_density": 0.1871476848375072, "a_collisions": 1613, "o_collisions": 0, "runtime": 995.6298495372757}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-060"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.08203125, "avg_agents_density": 0.2179619242653925, "a_collisions": 3521, "o_collisions": 0, "runtime": 697.599349886179}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-061"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9375, "avg_agents_density": 0.23839872112237379, "a_collisions": 4922, "o_collisions": 0, "runtime": 945.8460631053895}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-062"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.453125, "avg_agents_density": 0.3056663713981965, "a_collisions": 9677, "o_collisions": 0, "runtime": 990.0830775052309}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-063"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.703125, "avg_agents_density": 0.2219396539368482, "a_collisions": 2085, "o_collisions": 0, "runtime": 691.0634403666481}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-064"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6640625, "avg_agents_density": 0.3185038503288925, "a_collisions": 7963, "o_collisions": 0, "runtime": 960.9675385663286}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-065"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.27734375, "avg_agents_density": 0.24947403964317008, "a_collisions": 3014, "o_collisions": 0, "runtime": 865.0071008177474}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-066"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.46484375, "avg_agents_density": 0.17594174884322716, "a_collisions": 1678, "o_collisions": 0, "runtime": 795.6442294912413}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-067"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.30078125, "avg_agents_density": 0.21213811898696325, "a_collisions": 4511, "o_collisions": 0, "runtime": 736.3287452487275}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-068"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.28125, "avg_agents_density": 0.40384707320613905, "a_collisions": 9226, "o_collisions": 0, "runtime": 1196.0149976434186}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-069"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7421875, "avg_agents_density": 0.29635767102045313, "a_collisions": 7708, "o_collisions": 0, "runtime": 961.7427378026769}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-070"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.16796875, "avg_agents_density": 0.22262890044851752, "a_collisions": 2828, "o_collisions": 0, "runtime": 748.011826007627}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-071"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.91015625, "avg_agents_density": 0.1479952025382693, "a_collisions": 1104, "o_collisions": 0, "runtime": 824.9247163943946}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-072"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.79296875, "avg_agents_density": 0.2412388372018745, "a_collisions": 2540, "o_collisions": 0, "runtime": 793.0952365770936}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-073"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.96875, "avg_agents_density": 0.2164867286360279, "a_collisions": 5711, "o_collisions": 0, "runtime": 955.9844082929194}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-074"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.46484375, "avg_agents_density": 0.15436515661807867, "a_collisions": 2390, "o_collisions": 0, "runtime": 760.62702041585}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-075"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.98828125, "avg_agents_density": 0.25077515872264267, "a_collisions": 5794, "o_collisions": 0, "runtime": 886.3922149538994}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-076"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.546875, "avg_agents_density": 0.2962705617798005, "a_collisions": 8160, "o_collisions": 0, "runtime": 988.1255452111363}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-077"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.7734375, "avg_agents_density": 0.22900585993291753, "a_collisions": 2212, "o_collisions": 0, "runtime": 740.9020357113332}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-078"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.7578125, "avg_agents_density": 0.18335019250677842, "a_collisions": 2149, "o_collisions": 0, "runtime": 983.2358583854511}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-079"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.875, "avg_agents_density": 0.15225460882241743, "a_collisions": 1234, "o_collisions": 0, "runtime": 836.9027139097452}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-080"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.31640625, "avg_agents_density": 0.24039376016563793, "a_collisions": 4585, "o_collisions": 0, "runtime": 1156.2293582940474}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-081"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.9453125, "avg_agents_density": 0.23273644066947885, "a_collisions": 4114, "o_collisions": 0, "runtime": 758.2926585804671}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-082"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.3359375, "avg_agents_density": 0.18036686557188258, "a_collisions": 1722, "o_collisions": 0, "runtime": 924.0414659883827}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-083"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.74609375, "avg_agents_density": 0.24355128610788096, "a_collisions": 7620, "o_collisions": 0, "runtime": 909.9205125654116}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-084"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8203125, "avg_agents_density": 0.25579277367309433, "a_collisions": 6821, "o_collisions": 0, "runtime": 814.729694978334}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-085"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.30859375, "avg_agents_density": 0.19469098886329442, "a_collisions": 2077, "o_collisions": 0, "runtime": 842.7889223303646}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-086"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.7109375, "avg_agents_density": 0.25062632523993206, "a_collisions": 4945, "o_collisions": 0, "runtime": 836.78769940231}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-087"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.5078125, "avg_agents_density": 0.30690635593532267, "a_collisions": 8456, "o_collisions": 0, "runtime": 896.9379744688049}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-088"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.6484375, "avg_agents_density": 0.22993132275261424, "a_collisions": 2356, "o_collisions": 0, "runtime": 768.8322483366355}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-089"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.34375, "avg_agents_density": 0.23416247477569024, "a_collisions": 3363, "o_collisions": 0, "runtime": 746.8867865568027}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-090"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.66796875, "avg_agents_density": 0.24313784654108617, "a_collisions": 2498, "o_collisions": 0, "runtime": 808.5921362480149}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-091"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.07421875, "avg_agents_density": 0.18136596437337307, "a_collisions": 1905, "o_collisions": 0, "runtime": 955.0670186048374}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-092"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1328125, "avg_agents_density": 0.23074238112440945, "a_collisions": 3633, "o_collisions": 0, "runtime": 691.6733410079032}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-093"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.61328125, "avg_agents_density": 0.3072461423875105, "a_collisions": 8829, "o_collisions": 0, "runtime": 958.9516018694267}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-094"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.26171875, "avg_agents_density": 0.22109821238395222, "a_collisions": 2707, "o_collisions": 0, "runtime": 678.3292415738106}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-095"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.4296875, "avg_agents_density": 0.23538421743482282, "a_collisions": 2393, "o_collisions": 0, "runtime": 727.7767599159852}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-096"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.921875, "avg_agents_density": 0.27514880750752435, "a_collisions": 6584, "o_collisions": 0, "runtime": 900.8291666461155}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-097"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.078125, "avg_agents_density": 0.21566317654726305, "a_collisions": 3419, "o_collisions": 0, "runtime": 676.8244849704206}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-098"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.49609375, "avg_agents_density": 0.22031327121676317, "a_collisions": 2640, "o_collisions": 0, "runtime": 719.8585879290476}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-099"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.765625, "avg_agents_density": 0.22622264199354755, "a_collisions": 2423, "o_collisions": 0, "runtime": 767.7461684998125}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-100"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.3828125, "avg_agents_density": 0.22861387405188457, "a_collisions": 3365, "o_collisions": 0, "runtime": 832.8464005831629}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-101"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.671875, "avg_agents_density": 0.23134742376267436, "a_collisions": 3273, "o_collisions": 0, "runtime": 809.6631828397512}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-102"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1328125, "avg_agents_density": 0.23094274817509255, "a_collisions": 6270, "o_collisions": 0, "runtime": 1180.700380996801}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-103"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.03515625, "avg_agents_density": 0.248508063370057, "a_collisions": 3541, "o_collisions": 0, "runtime": 815.1951061980799}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-104"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.65234375, "avg_agents_density": 0.22726084411080513, "a_collisions": 6912, "o_collisions": 0, "runtime": 767.5396116385236}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-105"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.72265625, "avg_agents_density": 0.17630781510831495, "a_collisions": 1627, "o_collisions": 0, "runtime": 922.3608372574672}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-106"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.375, "avg_agents_density": 0.3582897921562463, "a_collisions": 9860, "o_collisions": 0, "runtime": 1256.9567577950656}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-107"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.44921875, "avg_agents_density": 0.22429865134458774, "a_collisions": 2865, "o_collisions": 0, "runtime": 774.6171506019309}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-108"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.90625, "avg_agents_density": 0.2404171399015402, "a_collisions": 4116, "o_collisions": 0, "runtime": 772.9816358108073}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-109"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.05859375, "avg_agents_density": 0.2288794069435696, "a_collisions": 3975, "o_collisions": 0, "runtime": 797.9227467393503}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-110"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.859375, "avg_agents_density": 0.2061346366249612, "a_collisions": 2329, "o_collisions": 0, "runtime": 971.5397575180978}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-111"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.75390625, "avg_agents_density": 0.2502743617846614, "a_collisions": 6217, "o_collisions": 0, "runtime": 905.2919361600652}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-112"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 3.3359375, "avg_agents_density": 0.21103953046998128, "a_collisions": 2137, "o_collisions": 0, "runtime": 1064.484334484674}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-113"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.68359375, "avg_agents_density": 0.22824143262000138, "a_collisions": 2457, "o_collisions": 0, "runtime": 1004.702280071564}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-114"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.1328125, "avg_agents_density": 0.20675135507799258, "a_collisions": 5719, "o_collisions": 0, "runtime": 755.8714360473678}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-115"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.0234375, "avg_agents_density": 0.2940403618695554, "a_collisions": 6007, "o_collisions": 0, "runtime": 953.1093724835664}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-116"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.12109375, "avg_agents_density": 0.232435786072866, "a_collisions": 2771, "o_collisions": 0, "runtime": 1001.607284732163}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-117"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.41796875, "avg_agents_density": 0.22120444924160915, "a_collisions": 2714, "o_collisions": 0, "runtime": 670.6050950959325}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-118"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.8125, "avg_agents_density": 0.24854298521057144, "a_collisions": 7006, "o_collisions": 0, "runtime": 927.7020091367885}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-119"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.95703125, "avg_agents_density": 0.15348765552725402, "a_collisions": 1562, "o_collisions": 0, "runtime": 781.7532579880208}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-120"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.9296875, "avg_agents_density": 0.22808462267532612, "a_collisions": 2469, "o_collisions": 0, "runtime": 815.8549127224833}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-121"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.26953125, "avg_agents_density": 0.17791518095839493, "a_collisions": 2104, "o_collisions": 0, "runtime": 825.1941499626264}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-122"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.76171875, "avg_agents_density": 0.25714384169985843, "a_collisions": 3604, "o_collisions": 0, "runtime": 1391.6058079777285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-123"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.6875, "avg_agents_density": 0.23132775981664092, "a_collisions": 4305, "o_collisions": 0, "runtime": 749.1455738898367}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-124"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 1.34375, "avg_agents_density": 0.23046005422920124, "a_collisions": 3001, "o_collisions": 0, "runtime": 767.4250336447731}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-125"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 0.24609375, "avg_agents_density": 0.2970748759350965, "a_collisions": 11430, "o_collisions": 0, "runtime": 1308.419402178377}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-126"}, "algorithm": "MATS-LP"}, {"metrics": {"avg_throughput": 2.10546875, "avg_agents_density": 0.2259332255430108, "a_collisions": 2794, "o_collisions": 0, "runtime": 954.0577687900513}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-127"}, "algorithm": "MATS-LP"}]